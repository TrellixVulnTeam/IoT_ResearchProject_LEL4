{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:07:53.870482Z",
     "start_time": "2019-11-15T16:07:53.625793Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython import get_ipython;   \n",
    "get_ipython().magic('reset -sf')\n",
    "#https://github.com/kirbs-/hide_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:07:53.890202Z",
     "start_time": "2019-11-15T16:07:53.876721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "%run -i Packages.py\n",
    "%matplotlib inline\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:07:53.918605Z",
     "start_time": "2019-11-15T16:07:53.895236Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(ggplot2)\n",
    "library(readr)\n",
    "library(lubridate)\n",
    "library(dplyr)\n",
    "library(tidyr)\n",
    "library(viridis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T09:32:09.845752Z",
     "start_time": "2019-11-02T09:32:09.647061Z"
    }
   },
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Example - from Service Mining on the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Web mining research focuses on applying data mining techniques to discover interesting patterns of data from the Web. In contrast, our research focuses on studying service behaviors that are intrinsically dynamic in nature, thus the need of dynamic invocation of services after the discovery of interesting service compositions. A comprehensive QoSbased service composition selection strategy is proposed in [8]. Our weighted function on usefulness ((12)) is based on this strategy. Ardagna and Pernici [18] take this a step further by considering the frequency of execution paths. In our framework, we don’t assume that such frequency is readily available. Xiong et al. [19] investigate how to configure Web services in a dynamically changing environment. In this regard, our research aims at the quick identification of best service compositions and thus focuses more on the initial selection of service compositions using usefulness measures. Lamparter et al. [20] rely heavily on user  references in the selection of Web services. Such preferences lead to a typical top-down service composition approach and are thus not taken advantage in our approach. A number of feedback and log-based approaches have been proposed to improve QoS and service composability measures. For example, Jurca et al. [21] propose a QoS monitoring scheme based on quality ratings from service clients, Dustdar and Hoffmann [22] rely on analyzing Web service execution log data to discover potential process workflow instances involving these services, and Liang et al. [23] rely on usage data at user, template, and instance levels to mine for Web service composition patterns. While these approaches may work well for business processes over time as user feedback and execution logs are expected to become available, the challenge of identifying interesting workflows in the absence of such feedback and logs, especially at the time when component Web services are just introduced, is still real. Our Web service mining framework allows the mining of interesting service compositions to be carried out in the absence of user feedback and execution logs. When applied to the field of pathway discovery, where the expedience of such discovery is the key to success, our approach enables the proactive discovery of interesting pathways upon the availability of these services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Example - from Cloud forecasting system for monitoring and alerting of energy use by home appliances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In recent years, numerous energy information systems have been developed using multiple data sources[21]. In particular, EIS for home appliances has been recently developed to facilitate the effective usage of electricity by end-users[3,22,23]. An EIS includes web-based soft-ware, data acquisition hardware, and a communication system that are used to store, analyze, and display building energy data[5,24]. Since EIS has many features related to energy control and electricity cost management, it can help users to reduce their electricity consumption <br>\n",
    "\n",
    "Bapat (2011), for instance, developed the Yupik system that enables users to respond to real-time electricity prices in a manner that is consistent with their lifestyle[25]. Yupik combines sensing, analytics,and an integer linear program to generate appliance usage schedules that can be used by households to minimize their energy bill and potential lifestyle disruptions[25]. Carlos (2012) developed a system that automates the remote metering and sub-metering of electricity and integrated it into a structured knowledge tool. It provided customers and utility companies with compiled reports of historical use, daily and hourly forecasts, and projected savings owing to changes in consumption habits and the use of more efficient equipment[26]. <br>\n",
    "\n",
    "The main purpose of smart metering is to encourage consumers to use less electricity by better informing them about their consumption patterns[27]. A smart meter, which is a critical component of a smart grid system, is an electrical meter that records energy consumption at intervals of an hour or less and sends the information to a utility center for monitoring and billing purposes[28]. Motivated by this fact, re-search in this area has grown substantially in recent years[29]. <br>\n",
    "\n",
    "Wang (2011) discussed various features and technologies that canbe integrated with a smart meter. He outlined various issues and challenges in the design, deployment, utilization, and maintenance ofsmart meter infrastructure[30]. Arghira (2012) proposed a stochastic method for predicting energy consumption over the next 24 h. He presented and tested basic predictors that were derived from the available historical data[31]. <br>\n",
    "\n",
    "Further, Yildiz et al. (2017) reviewed the most recently developed methods and techniques for using smart meter data in forecasting,clustering, classification and optimization. Their investigation covered various applications, such as Home and Battery Energy Management Systems, and demand response strategies that are enabled by the analysis of smart meter data[32]. Smart meters provide customers with detailed energy usage data in real time or in near real time[33]. <br>\n",
    "\n",
    "By using smart meters, Yip et al. (2018) presented a new anomaly detection method for evaluating consumers’ energy utilization to identify the localities of potential energy frauds and faulty meters. They introduced metrics called the loss factor and error term to estimate the technical losses and capture the measurement noise, respectively, in distribution lines and transformers[34]. <br>\n",
    "\n",
    "Another focus of EIS development is to store, analyze and display building energy data with the aid of cloud service[24]. With respect to energy management, several studies have utilized a web-based platform to assist users in managing and monitoring energy consumption more effectively. Kolokotsa et al. (2016) presented an efficient web-based energy management system for campuses that manages the campus buildings and public spaces; monitors the energy load of those buildings and performs energy consumption analysis for each building and the campus overall. It also interacts with each building’s main users through questionnaires, e-mails and forms[35]. <br>\n",
    "\n",
    "Wang et al. (2013) developed a web-based energy management application that runs on a development platform that is called the Smart Energy Management System which can monitor in real time the power consumption of designated devices or areas, and control loads. This system provides substantial value in energy-saving, demand-side management, and load profile modeling[36]. Kastner and Matthies (2014)presented a web-based intervention program for changing habitual energy-relevant behavior. The intervention was designed to provide recommendations for easily adopted energy-efficient behaviors to all staff members of the building[37]. <br>\n",
    "\n",
    "Noticeably, in the field of energy management, very few web-based systems integrated with statistical tools or data mining algorithms to predict and monitor energy consumption. Tabordaet al.(2015) developed a platform for predicting the energy consumption of commercial,industrial and residential buildings. The platform comprises prediction algorithms, which are supported by computational intelligence pro-grams[38]. Kris et al. (2017) proposed a web-based system for valuating the usability of a control interface for the energy-efficient management of public buildings, based on an intelligent generation method using ANNs and genetic algorithms[39]. Chou et al. (2017)developed a web-based system that collects data from sensors and displays on a dashboard based on those data[40]. <br>\n",
    "\n",
    "Although the above web-based energy management systems em-ployed AI techniques to forecast day-ahead energy consumption, there is still significant room for improvement on computing efficiency and accuracy. Building a web-based system that incorporates a hybrid AImodel fulfills such a goal by forecasting future values using historical time-series data[41,42]. During the construction of a hybrid model,optimization technique is often utilized to fine tune the hyperpara-meters of AI models. In particular, combining time-series techniques with machine learning models can appropriately capture the linear andnonlinear patterns of energy use. <br>\n",
    "\n",
    "Various time-series models such as the autoregressive integratedmoving average (ARIMA) and the seasonal ARIMA (SARIMA) modelshave been developed in the recent years[43]. The ARIMA models,developed by Box and Jenkins[44], are the most frequently used andeffective statistical tools for time-series forecasting[45], and they form an extensively used class of linear models for application to univariatetime series. Similarly, numerous academic and industrial applicationsof the SARIMA models have been developed in the last three decades[46]. <br>\n",
    "\n",
    "Drawing on the reviewed techniques and their advantages, this in-vestigation develops a web-based system that integrates a hybrid of theSARIMA and metaheuristicfirefly algorithm-based least squares sup-port vector regression (MetaFA-LSSVR)[20]for forecasting energyconsumption. The primary objective of the integrated techniques is to exploit the combined feature of linear (SARIMA) and nonlinear (Me-taFA-LSSVR) models to extract patterns in the time-series data. <br>\n",
    "\n",
    "Energy information systems in earlier studies have been unable to provide immediate warnings of anomalous energy consumption[40].By incorporating an automated prediction system, the web-based system can continuously forecast the following day’s electricity consumption. According to the forecasts and energy consumption that is recorded in real time, a monitoring system that detects, and warns users of, anomalous energy consumption can thus be developed.The proposed cloud forecasting system can immediately send an e-mail alert when anomalous energy consumption is detected, which can be received by users without their logging in to the system. By monitoring energy consumption in real time and receiving alerts about anomalous energy consumption, residents can proactively reduce the energy consumed by their appliances and electrical equipment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Activity Recognition in the Home Setting Using Simple and Ubiquitous sensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Emmaunael et al INSTALLED X NUMBER (unique subActNum) of reed switch sensors in a single-person apartment, collecting data about subject activity for a period of X days. The sensors were installed on, in and around everyday objects such as drawers, appliances, containers, fittings, etc to record opening-closing events (activation deactivation events) as the subject carried out everyday activities.\n",
    "\n",
    "The primary goal of this work was to consider if end-user sensor installation, as compared with professionally installed sensors, would have a material effect on the quality of the data being collected. The immediate consequence of data quality being, it's ability to be used in further downstream processing.\n",
    "\n",
    "For example, use of the data for context inference, which can then be exploited in novel applications for healthcare, communication, education, and entertainment.\n",
    "\n",
    "The primary goal of this work was efficacy XYZ ... It was found\n",
    "\n",
    "Emmanuel Munguia Tapia\n",
    "- E. Munguia Tapia. Activity Recognition in the Home Using Simple and Ubiquitous\n",
    " Sensors. Pervasive 2004,Vienna, Austria.\n",
    "- E. Munguia Tapia. Activity Recognition in the Home Setting Using Simple and \n",
    "Ubiquitous Sensors. S.M. Thesis, Massachusetts Institute of Technology, 2003.\n",
    "\n",
    "\n",
    "Each directory contains the data of a different subject and each subdirectory contains the following files: The data is stored in text format and coma separated values (.csv). To visualize the files, you can use Excel or Wordpad.\n",
    "\n",
    "Each directory contains the following files:\n",
    "\n",
    "1) sensors.csv\n",
    "\n",
    "file containing the sensor information in the following forma:\n",
    "\n",
    "SENSOR_ID,LOCATION,OBJECT\n",
    "\n",
    "example:\n",
    "\n",
    "100,Bathroom,Toilet Flush \n",
    "101,Bathroom,Light switch\n",
    "104,Foyer,Light switch\n",
    "...\n",
    "..\n",
    ".\n",
    "\n",
    "2)activities.csv\n",
    "\n",
    "is the file containing all the activities analyzed in the following format\n",
    "\n",
    "Heading,Category,Subcategory,Code\n",
    "\n",
    "example:\n",
    "\n",
    "Employment related,Employment work at home,Work at home,1\n",
    "Employment related,Travel employment,Going out to work,5\n",
    "Personal needs,Eating,Eating,10\n",
    "Personal needs,Personal hygiene,Toileting,15\n",
    "\n",
    "3)activities_data.csv\n",
    "\n",
    "is the data of the activities in the following format:\n",
    "\n",
    "ACTIVITY_LABEL,DATE,START_TIME,END_TIME\n",
    "SENSOR1_ID, SENSOR2_ID, ......\n",
    "SENSOR1_OBJECT,SENSOR2_OBJECT, .....\n",
    "SENSOR1_ACTIVATION_TIME,SENSOR2_ACTIVATION_TIME, .....\n",
    "SENSOR1_DEACTIVATION_TIME,SENSOR2_DEACTIVATION_TIME, .....\n",
    "\n",
    "where date is in the mm/dd/yyyy format\n",
    "where time is in the hh:mm:ss format\n",
    "\n",
    "\n",
    "NOTE: ACTIVITY_LABEL = Subcategory\n",
    "\n",
    "example:\n",
    "\n",
    "Toileting,17:30:36,17:46:41\n",
    "100,68\n",
    "Toilet Flush,Sink faucet - hot\n",
    "17:39:37,17:39:46\n",
    "18:10:57,17:39:52\n",
    "\n",
    "-Emmanuel Munguia Tapia [emunguia@media.mit.edu]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Convenience-Based Periodic Composition of IoT Services @article{huang2018}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Abstract** _We propose a novel service mining framework to personalize services in an IoT based smart home. We describe a new technique based on the concept ofconvenienceto discover periodic composite IoTservices to suit the smart home occupant’s convenience needs. The keyfeatures of convenience is the ability to model the spatio-temporal aspects as occupants move in time and space within the smart home. We propose a novel framework for the transient composition of spatio-temporal IoT service. We design two strategies to prune non-promising compositions. Specifically, a significance model is proposed to prune insignificant com-posite IoT services. We describe a spatio-temporalproximitytechniqueto prune loosely correlated composite IoT services. A periodic composite IoT service model is proposed to model theregularityof composite IoT services occurring at a certain location in a given time interval. The experimental results on real datasets show the efficiency and effectiveness of our proposed approach._\n",
    "<p style='text-align: justify;'> \n",
    "\n",
    "DISCUSS RESULTS\n",
    "\n",
    "<center>\n",
    "<img src=\"images/huangA.jpg\" title=\"Test Title\" alt=\"Alt text\" width=\"400\" height=\"400\" />\n",
    "</center> \n",
    "<i> This text is italic. </i> <br>\n",
    "Fig 1. DESCRIBE\n",
    "\n",
    "<center>\n",
    "    <img src=\"images/huangC.jpg\" title=\"Test Title\" alt=\"Alt text\" width=\"400\" height=\"400\" />\n",
    "    <i> Fig 1. The work of Huang et al provided initial direction for our data preprocessing. Because we had NO INFORMATION / IT IS A TINY APARTMENT - JUSTIFY the reason for alternate approach RE data processing \n",
    "    </i> \n",
    "    <br>\n",
    "</center> \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "S = \n",
    "<Seq,T,L> = \n",
    " \\begin{Bmatrix}\n",
    "  \\alpha_{1} & \\cdots & \\alpha_{i} & \\cdots & \\alpha_{2n} \\\\\n",
    "  t_{1}      & \\cdots & t_{i}      & \\cdots & t_{2n}      \\\\\n",
    "  l_{1}      & \\cdots & l_{i}      & \\cdots & l_{2n}      \\\\\n",
    " \\end{Bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    " \\begin{Bmatrix}\n",
    "  s_{2}^{+} & s_{1}^{+} & s_{3}^{+} & s_{1}^{-} & s_{3}^{-} & s_{2}^{-} \\\\\n",
    "  48        & 50        & 58        & 65        & 70        & 75        \\\\\n",
    "  l_{2}     & l_{1}     & l_{3}     & l_{1}     & l_{3}     & l_{2}     \\\\\n",
    " \\end{Bmatrix}\n",
    " (i.e., l_{1} = (1,2), l_{2} = (2,4), l_{3} = (3,5))\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Discovering Spatio-Temporal Relationships among IoT Services "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Conference paper version of _Convenience-Based Periodic Composition of IoT Services @article{huang2018}_\n",
    "\n",
    "We propose a framework to discover proximate IoT service relationships based on spatio-temporal features. We introduce a spatio-temporal proximity model in terms ofspatial-proximity and temporal-proximity to discard insigniﬁcant IoT service relationships. The proximity model focuses onquantifying the correlation strength among IoT services fromtime and location aspects. A new algorithm is proposed to discover proximate spatio-temporal IoT service relationships.\n",
    "Objective: Framework to discover proximate IoT service relationships based on spatio-temporal features / Quantify the correlation strength of among IoT services from time and location aspects\n",
    "Domain: Spatio-temporal relationships, IoT, Proximity, Spatio-temporal data, IoT service, high-level intelligence in smart homes, Service composition, Spatial and temporal correlation, Service Mining\n",
    "Input: Data from domestic IoT services (temporal, spatial)\n",
    "Technology: IoT, Sensors, Periodic Composite IoT Service Miner (PCMiner)\n",
    "Output: Spatio-temporal proximity model \n",
    "- Filter out insignificant spatio-temporal IoT service relationships\n",
    "Categories (e.g., objective):\n",
    "- Quantify the correlation strength of among IoT services from time and location aspects\n",
    "- IoT devices are highly heterogeneous in terms of supporting infrastructure ranging from networking to programming abstraction\n",
    "- Hiding (abstracting) complex and diverse supporting infrastructure\n",
    "- Proximity and correlation strength\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Service Mining for Internet of Things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "_A service mining framework is proposed that enables discovering interesting relationships in Internet of Things services bottom-up.The service relationships are modeled based on spatial-temporal aspects,environment, people, and operation. An ontology-based service model is proposed to describe services. We present a set of metrics to evaluate the interestingness of discovered service relationships. Analytical and simulation results are presented to show the effectiveness of the proposed evaluation measures._\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Service Mining on the Web @article{zheng2009}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "_The Web is transforming from a Web of data to a Web of both Semantic data and services. This trend is providing us with increasing opportunities to compose potentially interesting and useful services from existing services. While we may not sometimes have the specific queries needed in top-down service composition approaches to identify them, the early and proactive exposure of these opportunities will be key to harvest the great potential of the large body of Web services. In this paper, we propose a Web service mining framework that allows unexpected and interesting service compositions to automatically emerge in a bottom-up fashion. We present several mining techniques aiming at the discovery of such service compositions. We also present evaluation measures of their interestingness and usefulness. As a novel application of this framework, we demonstrate its effectiveness and potential by applying it to service-oriented models of biological processes for the discovery of interesting and useful pathways._ \n",
    "\n",
    "#### Objective\n",
    "Zheng et al use the top-down, bottom-up paradigm in this context to describe two scenarios. The first scenario is the 'as is' state when interacting with the internet, whereby a users must provide a goal containing specific search criteria defining the exact service functionality expected (to be provisioned to the end user in some way). Zheng et al highlight the paradoxical notion (synonym???) that specificity of search criteria reflects the interests and often knowledge of the service composer about potential composability, however the composers is only typically aware of and consequently interested in specific types of compositions, thus narrowing the search and preventing the discovery by the end user of a better composition of services.\n",
    "- Top down works well when the end user knows what they want exactly\n",
    "- The concept of the 'full potential' of the 'service space'\n",
    "_Instead of starting the search with a specific goal, a service engineer may be interested in discovering any interesting and useful service compositions that may come up in the search process._\n",
    "\n",
    "_specific_\n",
    "\n",
    "_Web service mining faces two main challenges, namely, combinatorial explosion and evaluation of interestingness and usefulness._\n",
    "\n",
    "<center>\n",
    "    <img src=\"images/serviceMining.png\" title=\"Test Title\" alt=\"Alt text\" width=\"400\" height=\"400\" />\n",
    "    <i> Fig 1.  </i> \n",
    "</center> \n",
    "\n",
    "<center>\n",
    "    <img src=\"images/serviceMining2.png\" title=\"Test Title\" alt=\"Alt text\" width=\"400\" height=\"400\" />\n",
    "    <i> Fig 1.   </i> \n",
    "</center> \n",
    "\n",
    "\n",
    "\n",
    "#### Input\n",
    "Web Service Operation, \n",
    "\n",
    "#### Technology\n",
    "Service mining tool, Web Service Mining\n",
    "\n",
    "#### Output\n",
    "Composed Web Services\n",
    "\n",
    "**Evaluation - Operational Similarity & Domain Correlation and Unrelatedness & Objective Usefullness**\n",
    "\n",
    "#### Notes\n",
    "\n",
    "<center>\n",
    "    <img src=\"images/compo.png\" title=\"Test Title\" alt=\"Alt text\" width=\"400\" height=\"400\" />\n",
    "    <i> Fig 1.   </i> \n",
    "</center> \n",
    "\n",
    "#### Discussion example\n",
    "We are able to greatly simplify all 'downstream analysis' with our approach. For example, @article{zheng2009} in Service Mining on the Web propose service mining metric including _Operational Similarity_ (the similarity of two operations can be measured by comparing their input parameter set, output parameter set, preconditions and postconditions, range of 0 till 1). _Domain Correlation and Unrelatedness_ (DC measures the relevance of two domains di and dj, or the cohesion of the same domain, when i = j. The relevance of di and dj can be reflected by the composability among operations from the two domains. ) \n",
    "\n",
    "\n",
    "Web Service Composition\n",
    "* Aims at providing value-added services through composing existing services\n",
    "* Traditionally taken a ‘top-down’ approach\n",
    "* Challenge: If the search terms are to specific the user may not be able to find an appropriate composed service\n",
    "* ‘Bottom-up’ approach also possible\n",
    "* E.g., Aim to discover any interesting and useful services with a general interest in Chinese medicine in mind, using a Service Mining Tool, may find – A service composition that takes as input a biological sample from a subject, determined the corresponding genome and the possible diseases the subject is predisposed to, and finally generates a list of treatment recommendation and/or life style suggestions.\n",
    "* Bottom-up is ‘serendipidous’ in nature, has the ability of finding unexpected interesting and useful service compositions\n",
    "* It is essential to be able to proactively discover opportunities for composing useful services, even when the goals are unspecified at the moment, or simply hard to imagine or unknown\n",
    "* Much like the easy access to a glut of data has provided a fertile ground for data mining research, there is an expectation that an increase in Web services’ availability will also spur both the need and opportunities to break new ground on Web Services Mining\n",
    "* We define Web Service Mining as a bottom-up search process aimed at the proactive discovery of potentially interesting and useful web services from existing services.\n",
    "* Two Main Challenges\n",
    "1. Combinatorial Explosion\n",
    "2. Evaluation of interestingness and usefulness\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Appliance Usage Prediction Using a Time Series Based Classification Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Cloud forecasting system for monitoring and alerting of energy use by home appliances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/chou.png\" title=\"Test Title\" alt=\"Alt text\" width=\"700\" height=\"700\" />\n",
    "    <i> Fig 1.   </i> \n",
    "</center> \n",
    "\n",
    "\n",
    "<center>\n",
    "    <img src=\"images/chou2.png\" title=\"Test Title\" alt=\"Alt text\" width=\"700\" height=\"700\" />\n",
    "    <i> Fig 1.   </i> \n",
    "</center> \n",
    "\n",
    "<center>\n",
    "    <img src=\"images/chou1.png\" title=\"Test Title\" alt=\"Alt text\" width=\"700\" height=\"700\" />\n",
    "    <i> Fig 1.   </i> \n",
    "</center> \n",
    "\n",
    "<center>\n",
    "    <img src=\"images/chou3.png\" title=\"Test Title\" alt=\"Alt text\" width=\"700\" height=\"700\" />\n",
    "    <i> Fig 1.   </i> \n",
    "</center> \n",
    "\n",
    "<center>\n",
    "    <img src=\"images/chou4.png\" title=\"Test Title\" alt=\"Alt text\" width=\"700\" height=\"700\" />\n",
    "    <i> Fig 1.   </i> \n",
    "</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing & Preprocessing the Activities Meta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:01.971395Z",
     "start_time": "2019-11-15T16:08:01.968262Z"
    }
   },
   "outputs": [],
   "source": [
    "# ds = pd.read_csv(PATH + '/datasets/S1Activities.csv', index_col = 'Code') \n",
    "# ds.head(n=5)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing & Preprocessing the Sensor Meta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:02.299415Z",
     "start_time": "2019-11-15T16:08:02.285601Z"
    }
   },
   "outputs": [],
   "source": [
    "dsS1Sensors = pd.read_csv(PATH + '/datasets/S1sensors.csv', \n",
    "                           dtype={0:str, 1:str, 2:str},\n",
    "                           index_col = None, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:02.324969Z",
     "start_time": "2019-11-15T16:08:02.303216Z"
    }
   },
   "outputs": [],
   "source": [
    "%run -i S1sensorsPreprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:02.342345Z",
     "start_time": "2019-11-15T16:08:02.332265Z"
    }
   },
   "outputs": [],
   "source": [
    "%run -i getUniqueValues.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:02.361500Z",
     "start_time": "2019-11-15T16:08:02.346770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3   kitchen_lightswitch\n",
      "4   kitchen_burner\n",
      "2   livingroom_lightswitch\n",
      "7   kitchen_drawer\n",
      "3   kitchen_refrigerator\n",
      "15  kitchen_cabinet\n",
      "2   kitchen_door\n",
      "5   bedroom_drawer\n",
      "2   bathroom_medicinecabinet\n",
      "2   bathroom_cabinet\n"
     ]
    }
   ],
   "source": [
    "%run -i seen_dupes_dsS1Sensors.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:02.374535Z",
     "start_time": "2019-11-15T16:08:02.364143Z"
    }
   },
   "outputs": [],
   "source": [
    "%run -i reqEnergy_containSpecialChar.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:02.390749Z",
     "start_time": "2019-11-15T16:08:02.377136Z"
    }
   },
   "outputs": [],
   "source": [
    "%run -i reqEnergy_containSpecialCharClean.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:02.405598Z",
     "start_time": "2019-11-15T16:08:02.393927Z"
    }
   },
   "outputs": [],
   "source": [
    "%run -i sensorDataJSONwDUPES.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example DUPES Dupes not dropped (no point) (????)** <br>\n",
    "132,Kitchen,Cabinet,kitchen_cabinet,False,subActNum_132 <br>\n",
    "133,Kitchen,Cabinet,kitchen_cabinet,False,subActNum_133"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:02.734115Z",
     "start_time": "2019-11-15T16:08:02.725632Z"
    }
   },
   "outputs": [],
   "source": [
    "dsS1Sensors.to_csv(PATH + '/intermediate_datasets/S1Sensors_preprocessed.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing & Preprocessing the Activities Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:03.141178Z",
     "start_time": "2019-11-15T16:08:03.100717Z"
    }
   },
   "outputs": [],
   "source": [
    "dsS1 = pd.read_csv(PATH + '/datasets/S1activities_data.csv', sep = 'delimiter', header = None, engine = 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:03.154663Z",
     "start_time": "2019-11-15T16:08:03.144876Z"
    }
   },
   "outputs": [],
   "source": [
    "#dsS1.loc[[5,6,7,8,9],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:03.178775Z",
     "start_time": "2019-11-15T16:08:03.167777Z"
    }
   },
   "outputs": [],
   "source": [
    "#dsS1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:03.202091Z",
     "start_time": "2019-11-15T16:08:03.185748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1475"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirming the length of the dataframe\n",
    "len(dsS1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:03.312781Z",
     "start_time": "2019-11-15T16:08:03.213350Z"
    }
   },
   "outputs": [],
   "source": [
    "%run -i dsS1Activities_processing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:03.334822Z",
     "start_time": "2019-11-15T16:08:03.320551Z"
    }
   },
   "outputs": [],
   "source": [
    "#dsIntermediate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:03.368628Z",
     "start_time": "2019-11-15T16:08:03.351439Z"
    }
   },
   "outputs": [],
   "source": [
    "#ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:03.389986Z",
     "start_time": "2019-11-15T16:08:03.373351Z"
    }
   },
   "outputs": [],
   "source": [
    "ds.to_csv(PATH + '/intermediate_datasets/S1Activities_preprocessed.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing, Visualizing and Preprocessing the SubActivities Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:04.423697Z",
     "start_time": "2019-11-15T16:08:03.958403Z"
    }
   },
   "outputs": [],
   "source": [
    "%run -i dsS1SubActivities_processing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:04.432847Z",
     "start_time": "2019-11-15T16:08:04.427837Z"
    }
   },
   "outputs": [],
   "source": [
    "#dsIntermediate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:04.456967Z",
     "start_time": "2019-11-15T16:08:04.435554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subActNum</th>\n",
       "      <th>subAct</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>Cabinet</td>\n",
       "      <td>2003-03-27 06:43:40</td>\n",
       "      <td>2003-03-27 06:43:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>Toilet Flush</td>\n",
       "      <td>2003-03-27 06:44:06</td>\n",
       "      <td>2003-03-27 07:12:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>Light switch</td>\n",
       "      <td>2003-03-27 06:44:20</td>\n",
       "      <td>2003-03-27 07:46:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>Medicine cabinet</td>\n",
       "      <td>2003-03-27 06:44:35</td>\n",
       "      <td>2003-03-27 06:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>Medicine cabinet</td>\n",
       "      <td>2003-03-27 06:44:36</td>\n",
       "      <td>2003-03-27 06:44:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subActNum            subAct               start                 end\n",
       "0         67           Cabinet 2003-03-27 06:43:40 2003-03-27 06:43:43\n",
       "1        100      Toilet Flush 2003-03-27 06:44:06 2003-03-27 07:12:41\n",
       "2        101      Light switch 2003-03-27 06:44:20 2003-03-27 07:46:34\n",
       "3         57  Medicine cabinet 2003-03-27 06:44:35 2003-03-27 06:44:48\n",
       "4         58  Medicine cabinet 2003-03-27 06:44:36 2003-03-27 06:44:48"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub Activity Preprocessing - Duplicate sub activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:04.609565Z",
     "start_time": "2019-11-15T16:08:04.584541Z"
    }
   },
   "outputs": [],
   "source": [
    "%run -i cleanDupesSubAct.py\n",
    "#%run -i add_DAY_WDWE_phaseII.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:04.634499Z",
     "start_time": "2019-11-15T16:08:04.615863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subActNum</th>\n",
       "      <th>subAct</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>bathroom_cabinet</td>\n",
       "      <td>2003-03-27 06:43:40</td>\n",
       "      <td>2003-03-27 06:43:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>bathroom_toiletflush</td>\n",
       "      <td>2003-03-27 06:44:06</td>\n",
       "      <td>2003-03-27 07:12:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>bathroom_lightswitch</td>\n",
       "      <td>2003-03-27 06:44:20</td>\n",
       "      <td>2003-03-27 07:46:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>bathroom_medicinecabinet</td>\n",
       "      <td>2003-03-27 06:44:35</td>\n",
       "      <td>2003-03-27 06:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>bathroom_medicinecabinet</td>\n",
       "      <td>2003-03-27 06:44:36</td>\n",
       "      <td>2003-03-27 06:44:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subActNum                    subAct               start                 end\n",
       "0         67          bathroom_cabinet 2003-03-27 06:43:40 2003-03-27 06:43:43\n",
       "1        100      bathroom_toiletflush 2003-03-27 06:44:06 2003-03-27 07:12:41\n",
       "2        101      bathroom_lightswitch 2003-03-27 06:44:20 2003-03-27 07:46:34\n",
       "3         57  bathroom_medicinecabinet 2003-03-27 06:44:35 2003-03-27 06:44:48\n",
       "4         58  bathroom_medicinecabinet 2003-03-27 06:44:36 2003-03-27 06:44:48"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the `ds.subAct` values with `dsS1Sensors.concat` values using the `subActNum` key\n",
    "* Join OR\n",
    "* Dict? USE THIS - cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:05.161879Z",
     "start_time": "2019-11-15T16:08:05.146927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[91, 126, 144]\n"
     ]
    }
   ],
   "source": [
    "%run -i refrigeratorDupes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:05.177508Z",
     "start_time": "2019-11-15T16:08:05.165076Z"
    }
   },
   "outputs": [],
   "source": [
    "%run -i removeDupesJSON.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:05.199341Z",
     "start_time": "2019-11-15T16:08:05.186238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[126]\n"
     ]
    }
   ],
   "source": [
    "%run -i refrigeratorDupes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:05.209166Z",
     "start_time": "2019-11-15T16:08:05.202603Z"
    }
   },
   "outputs": [],
   "source": [
    "#subActNumKeyWithStringDictNoDupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:05.317831Z",
     "start_time": "2019-11-15T16:08:05.212715Z"
    }
   },
   "outputs": [],
   "source": [
    "ds.to_csv(PATH + '/intermediate_datasets/S1SubActivities_preprocessed.csv', index = False)\n",
    "%run add_DAY_WDWE_phaseI.py\n",
    "ds = add_DAY_WDWE_phaseI(ds)\n",
    "ds.to_csv(PATH + '/intermediate_datasets/S1SubActivities_preprocessedWfeatures.csv', index = False)\n",
    "# 2019-11-13 - ADDED + 1 to add_DAY_WDWE_phaseI.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SubActivity Preprocessing Comparison and Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:06.150597Z",
     "start_time": "2019-11-15T16:08:06.146445Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %%R\n",
    "# ds <- read_csv('S1SubActivities_preprocessedR.csv', col_types = cols(subActNum = col_character(),\n",
    "#                                                                      dayNumeric = col_character(),\n",
    "#                                                                      HOUR = col_character()))\n",
    "# ds$start <- ymd_hms(ds$start)\n",
    "# ds$start <- force_tz(ds$start, \"America/New_York\")\n",
    "# ds$end <- ymd_hms(ds$end)\n",
    "# ds$end <- force_tz(ds$end, \"America/New_York\")\n",
    "# ds$subAct <- as.factor(ds$subAct)\n",
    "\n",
    "# total_counts <- ds %>% group_by(DAY, subAct) %>% summarise(count=n())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Aggregated Line Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:06.560956Z",
     "start_time": "2019-11-15T16:08:06.557032Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %%R\n",
    "# p <- ggplot(total_counts, aes(x = subAct, y = count, group = DAY, color = DAY))\n",
    "# p <- p + geom_line()\n",
    "# p <- p + geom_point()\n",
    "# p <- p + coord_flip() + labs(title = \"Plot of SubActivity Count versus SubActivity\",\n",
    "#                              subtitle = \"ADD SUBTITLE - Preprocessing Stage?\",\n",
    "#                              caption = \"Source: TBU\",\n",
    "#                              x = \"SubActivity\",\n",
    "#                              y = \"Aggregated Count\")\n",
    "# ggsave(\"images/lineChart.png\", plot = last_plot(), device = png(), \n",
    "#        scale = 1.5, width = 18, height = 16, units = c(\"cm\"), dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "<img src=\"images/lineChart.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "<i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Aggregated Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:07.367794Z",
     "start_time": "2019-11-15T16:08:07.359537Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %%R\n",
    "# p <- ggplot(ds, aes(subAct, durationSec))\n",
    "# p <- p + geom_boxplot(fill= \"plum\", outlier.alpha = 0.8) # aes(colour = WDWE) #, outlier.size = 1\n",
    "# p <- p + theme(legend.position = \"right\") + coord_flip() +\n",
    "#   labs(title = \"Box Plots\",\n",
    "#        subtitle = \"Subactivity Duraiton\",\n",
    "#        caption = \"Source: TBU\",\n",
    "#        x = \"SubActivity\",\n",
    "#        y = \"Duration (sec)\")\n",
    "# ggsave(\"images/boxPlots.png\", plot = last_plot(), device = png(), \n",
    "#        scale = 1.5, width = 18, height = 16, units = c(\"cm\"), dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "<img src=\"images/boxPlots.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "<i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strip Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:09.232503Z",
     "start_time": "2019-11-15T16:08:08.131018Z"
    }
   },
   "outputs": [],
   "source": [
    "%run -i altairDurationCharts.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:09.273614Z",
     "start_time": "2019-11-15T16:08:09.239754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.vegalite.v3+json": {
       "$schema": "https://vega.github.io/schema/vega-lite/v3.4.0.json",
       "config": {
        "background": "white",
        "mark": {
         "tooltip": null
        },
        "view": {
         "height": 300,
         "width": 400
        }
       },
       "data": {
        "name": "data-a92ac1bde1a73d84417dee493c5e5a06"
       },
       "datasets": {
        "data-a92ac1bde1a73d84417dee493c5e5a06": [
         {
          "day": "3",
          "end": "2003-03-27T07:12:41",
          "index": 1,
          "start": "2003-03-27T06:44:06"
         },
         {
          "day": "3",
          "end": "2003-03-27T12:26:27",
          "index": 17,
          "start": "2003-03-27T07:34:47"
         },
         {
          "day": "3",
          "end": "2003-03-27T18:41:03",
          "index": 77,
          "start": "2003-03-27T17:43:13"
         },
         {
          "day": "4",
          "end": "2003-03-28T16:34:50",
          "index": 98,
          "start": "2003-03-28T12:31:01"
         },
         {
          "day": "4",
          "end": "2003-03-28T16:34:50",
          "index": 99,
          "start": "2003-03-28T12:31:01"
         },
         {
          "day": "4",
          "end": "2003-03-28T18:37:06",
          "index": 126,
          "start": "2003-03-28T17:42:41"
         },
         {
          "day": "4",
          "end": "2003-03-28T22:16:00",
          "index": 168,
          "start": "2003-03-28T20:51:02"
         },
         {
          "day": "4",
          "end": "2003-03-28T22:16:00",
          "index": 169,
          "start": "2003-03-28T20:51:02"
         },
         {
          "day": "5",
          "end": "2003-03-29T08:24:52",
          "index": 206,
          "start": "2003-03-29T08:24:51"
         },
         {
          "day": "5",
          "end": "2003-03-29T09:45:17",
          "index": 207,
          "start": "2003-03-29T08:55:18"
         },
         {
          "day": "5",
          "end": "2003-03-29T15:37:10",
          "index": 243,
          "start": "2003-03-29T12:00:31"
         },
         {
          "day": "5",
          "end": "2003-03-29T15:43:20",
          "index": 510,
          "start": "2003-03-29T15:43:19"
         },
         {
          "day": "5",
          "end": "2003-03-29T17:13:54",
          "index": 641,
          "start": "2003-03-29T16:48:03"
         },
         {
          "day": "5",
          "end": "2003-03-29T22:16:01",
          "index": 645,
          "start": "2003-03-29T18:19:51"
         },
         {
          "day": "5",
          "end": "2003-03-29T22:28:41",
          "index": 679,
          "start": "2003-03-29T22:28:40"
         },
         {
          "day": "5",
          "end": "2003-03-29T23:10:49",
          "index": 685,
          "start": "2003-03-29T23:10:48"
         },
         {
          "day": "6",
          "end": "2003-03-30T08:01:56",
          "index": 722,
          "start": "2003-03-30T08:01:55"
         },
         {
          "day": "6",
          "end": "2003-03-30T08:44:10",
          "index": 724,
          "start": "2003-03-30T08:14:05"
         },
         {
          "day": "6",
          "end": "2003-03-30T12:45:21",
          "index": 740,
          "start": "2003-03-30T11:00:19"
         },
         {
          "day": "6",
          "end": "2003-03-30T13:19:01",
          "index": 760,
          "start": "2003-03-30T13:05:48"
         },
         {
          "day": "6",
          "end": "2003-03-30T21:10:42",
          "index": 806,
          "start": "2003-03-30T15:52:34"
         },
         {
          "day": "0",
          "end": "2003-03-31T09:13:45",
          "index": 839,
          "start": "2003-03-31T08:58:54"
         },
         {
          "day": "0",
          "end": "2003-03-31T17:13:53",
          "index": 865,
          "start": "2003-03-31T12:05:27"
         },
         {
          "day": "0",
          "end": "2003-03-31T19:43:39",
          "index": 888,
          "start": "2003-03-31T19:36:38"
         },
         {
          "day": "1",
          "end": "2003-04-01T06:57:39",
          "index": 901,
          "start": "2003-04-01T06:14:36"
         },
         {
          "day": "1",
          "end": "2003-04-01T16:35:49",
          "index": 938,
          "start": "2003-04-01T11:55:43"
         },
         {
          "day": "1",
          "end": "2003-04-01T18:10:57",
          "index": 961,
          "start": "2003-04-01T17:39:37"
         },
         {
          "day": "1",
          "end": "2003-04-01T21:05:20",
          "index": 965,
          "start": "2003-04-01T20:51:52"
         },
         {
          "day": "1",
          "end": "2003-04-01T23:10:23",
          "index": 981,
          "start": "2003-04-01T21:21:13"
         },
         {
          "day": "2",
          "end": "2003-04-02T11:25:03",
          "index": 994,
          "start": "2003-04-02T07:13:48"
         },
         {
          "day": "2",
          "end": "2003-04-02T16:44:37",
          "index": 1119,
          "start": "2003-04-02T12:12:04"
         },
         {
          "day": "3",
          "end": "2003-04-03T08:05:19",
          "index": 1197,
          "start": "2003-04-03T08:05:17"
         },
         {
          "day": "3",
          "end": "2003-04-03T09:26:08",
          "index": 1204,
          "start": "2003-04-03T08:47:33"
         },
         {
          "day": "3",
          "end": "2003-04-03T17:47:37",
          "index": 1265,
          "start": "2003-04-03T13:57:31"
         },
         {
          "day": "3",
          "end": "2003-04-03T22:08:48",
          "index": 1311,
          "start": "2003-04-03T20:20:51"
         },
         {
          "day": "4",
          "end": "2003-04-04T06:42:22",
          "index": 1342,
          "start": "2003-04-04T06:12:20"
         },
         {
          "day": "4",
          "end": "2003-04-04T14:02:12",
          "index": 1419,
          "start": "2003-04-04T12:30:30"
         },
         {
          "day": "4",
          "end": "2003-04-04T14:02:12",
          "index": 1420,
          "start": "2003-04-04T12:30:30"
         },
         {
          "day": "4",
          "end": "2003-04-04T16:43:31",
          "index": 1454,
          "start": "2003-04-04T14:56:40"
         },
         {
          "day": "5",
          "end": "2003-04-05T17:23:41",
          "index": 1603,
          "start": "2003-04-05T16:09:08"
         },
         {
          "day": "5",
          "end": "2003-04-05T20:27:32",
          "index": 1630,
          "start": "2003-04-05T17:57:19"
         },
         {
          "day": "5",
          "end": "2003-04-05T22:45:58",
          "index": 1657,
          "start": "2003-04-05T22:16:30"
         },
         {
          "day": "5",
          "end": "2003-04-05T22:45:58",
          "index": 1658,
          "start": "2003-04-05T22:16:30"
         },
         {
          "day": "6",
          "end": "2003-04-06T08:19:47",
          "index": 1687,
          "start": "2003-04-06T08:04:57"
         },
         {
          "day": "6",
          "end": "2003-04-06T09:42:16",
          "index": 1697,
          "start": "2003-04-06T08:53:48"
         },
         {
          "day": "6",
          "end": "2003-04-06T16:57:15",
          "index": 1800,
          "start": "2003-04-06T15:33:28"
         },
         {
          "day": "6",
          "end": "2003-04-06T17:39:31",
          "index": 1813,
          "start": "2003-04-06T17:38:08"
         },
         {
          "day": "6",
          "end": "2003-04-06T18:16:06",
          "index": 1817,
          "start": "2003-04-06T17:39:32"
         },
         {
          "day": "6",
          "end": "2003-04-06T18:22:56",
          "index": 1826,
          "start": "2003-04-06T18:17:47"
         },
         {
          "day": "6",
          "end": "2003-04-06T21:36:22",
          "index": 1873,
          "start": "2003-04-06T20:58:32"
         },
         {
          "day": "0",
          "end": "2003-04-07T07:11:58",
          "index": 1880,
          "start": "2003-04-07T04:40:01"
         },
         {
          "day": "0",
          "end": "2003-04-07T07:53:49",
          "index": 1900,
          "start": "2003-04-07T07:29:55"
         },
         {
          "day": "0",
          "end": "2003-04-07T16:41:39",
          "index": 1956,
          "start": "2003-04-07T13:14:18"
         },
         {
          "day": "0",
          "end": "2003-04-07T17:45:55",
          "index": 1970,
          "start": "2003-04-07T16:43:29"
         },
         {
          "day": "0",
          "end": "2003-04-07T20:17:55",
          "index": 1994,
          "start": "2003-04-07T18:51:34"
         },
         {
          "day": "0",
          "end": "2003-04-07T20:17:55",
          "index": 1995,
          "start": "2003-04-07T18:51:34"
         },
         {
          "day": "1",
          "end": "2003-04-08T11:26:00",
          "index": 2039,
          "start": "2003-04-08T07:10:13"
         },
         {
          "day": "1",
          "end": "2003-04-08T17:16:43",
          "index": 2066,
          "start": "2003-04-08T15:41:39"
         },
         {
          "day": "1",
          "end": "2003-04-08T21:16:11",
          "index": 2098,
          "start": "2003-04-08T20:54:30"
         },
         {
          "day": "2",
          "end": "2003-04-09T08:05:49",
          "index": 2135,
          "start": "2003-04-09T07:12:47"
         },
         {
          "day": "2",
          "end": "2003-04-09T10:54:55",
          "index": 2148,
          "start": "2003-04-09T08:43:32"
         },
         {
          "day": "2",
          "end": "2003-04-09T16:03:54",
          "index": 2234,
          "start": "2003-04-09T15:07:49"
         },
         {
          "day": "2",
          "end": "2003-04-09T18:44:58",
          "index": 2257,
          "start": "2003-04-09T16:23:59"
         },
         {
          "day": "2",
          "end": "2003-04-09T20:11:12",
          "index": 2279,
          "start": "2003-04-09T19:44:39"
         },
         {
          "day": "2",
          "end": "2003-04-09T21:37:58",
          "index": 2298,
          "start": "2003-04-09T21:20:20"
         },
         {
          "day": "2",
          "end": "2003-04-09T21:37:58",
          "index": 2299,
          "start": "2003-04-09T21:20:20"
         },
         {
          "day": "3",
          "end": "2003-04-10T11:20:51",
          "index": 2306,
          "start": "2003-04-10T08:19:09"
         },
         {
          "day": "3",
          "end": "2003-04-10T13:02:12",
          "index": 2457,
          "start": "2003-04-10T13:00:03"
         },
         {
          "day": "3",
          "end": "2003-04-10T14:43:00",
          "index": 2468,
          "start": "2003-04-10T13:23:47"
         },
         {
          "day": "3",
          "end": "2003-04-10T18:29:51",
          "index": 2487,
          "start": "2003-04-10T18:02:46"
         },
         {
          "day": "3",
          "end": "2003-04-10T19:59:44",
          "index": 2516,
          "start": "2003-04-10T19:16:03"
         },
         {
          "day": "3",
          "end": "2003-04-10T19:59:44",
          "index": 2517,
          "start": "2003-04-10T19:16:03"
         },
         {
          "day": "3",
          "end": "2003-04-10T21:11:10",
          "index": 2538,
          "start": "2003-04-10T20:28:23"
         },
         {
          "day": "4",
          "end": "2003-04-11T08:26:12",
          "index": 2556,
          "start": "2003-04-11T08:26:11"
         },
         {
          "day": "4",
          "end": "2003-04-11T09:07:45",
          "index": 2560,
          "start": "2003-04-11T09:06:17"
         },
         {
          "day": "4",
          "end": "2003-04-11T09:40:21",
          "index": 2563,
          "start": "2003-04-11T09:40:20"
         },
         {
          "day": "4",
          "end": "2003-04-11T17:47:59",
          "index": 2699,
          "start": "2003-04-11T15:55:13"
         },
         {
          "day": "4",
          "end": "2003-04-11T17:47:59",
          "index": 2700,
          "start": "2003-04-11T15:55:13"
         },
         {
          "day": "4",
          "end": "2003-04-11T20:04:54",
          "index": 2720,
          "start": "2003-04-11T19:31:10"
         }
        ]
       },
       "encoding": {
        "color": {
         "condition": {
          "test": "(datum.day > 4)",
          "value": "orange"
         },
         "value": "grey"
        },
        "detail": {
         "field": "index",
         "type": "quantitative"
        },
        "x": {
         "field": "start",
         "timeUnit": "hoursminutes",
         "type": "temporal"
        },
        "x2": {
         "field": "end",
         "timeUnit": "hoursminutes"
        },
        "y": {
         "field": "start",
         "timeUnit": "date",
         "type": "ordinal"
        }
       },
       "mark": "bar",
       "selection": {
        "selector040": {
         "bind": "scales",
         "encodings": [
          "x",
          "y"
         ],
         "type": "interval"
        }
       },
       "title": "Sub-activity: bathroom_toiletflush // Sub-activity number: 100",
       "width": 680
      },
      "text/plain": [
       "<VegaLite 3 object>\n",
       "\n",
       "If you see this message, it means the renderer has not been properly enabled\n",
       "for the frontend that you are using. For more information, see\n",
       "https://altair-viz.github.io/user_guide/troubleshooting.html\n"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example charts\n",
    "charts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:12.257916Z",
     "start_time": "2019-11-15T16:08:09.276429Z"
    }
   },
   "outputs": [],
   "source": [
    "charts[1].save('images/strip1.png', scale_factor=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SubActivity Cleansing - Outlier Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:12.265982Z",
     "start_time": "2019-11-15T16:08:12.261260Z"
    }
   },
   "outputs": [],
   "source": [
    "# Toilet Duration Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:12.288019Z",
     "start_time": "2019-11-15T16:08:12.269313Z"
    }
   },
   "outputs": [],
   "source": [
    "%run -i cleanToilet.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:12.298737Z",
     "start_time": "2019-11-15T16:08:12.290140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "%run -i countUnique.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:12.318380Z",
     "start_time": "2019-11-15T16:08:12.302854Z"
    }
   },
   "outputs": [],
   "source": [
    "# Jewelry + foyer closet + cereal + containers + lamp\n",
    "%run -i valueDrop.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:12.330136Z",
     "start_time": "2019-11-15T16:08:12.320894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "%run -i countUnique.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:12.368964Z",
     "start_time": "2019-11-15T16:08:12.332328Z"
    }
   },
   "outputs": [],
   "source": [
    "# NAME CHANGE?\n",
    "ds.to_csv(PATH + '/intermediate_datasets/S1SubActivities_temporalFeaturesNoDUPES.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling outliers with Median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on strip plot and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:12.378473Z",
     "start_time": "2019-11-15T16:08:12.371593Z"
    }
   },
   "outputs": [],
   "source": [
    "subActNames = ['bathroom_cabinet', 'bathroom_medicinecabinet', 'study_drawer',\n",
    "               'bedroom_drawer', 'kitchen_cabinet', 'kitchen_microwave',\n",
    "               'kitchen_door', 'bathroom_showerfaucet', 'kitchen_drawer',\n",
    "               'bathroom_sinkfaucet-hot', 'kitchen_freezer', 'bathroom_door',\n",
    "               'kitchen_toaster', 'kitchen_lightswitch', 'study_lightwitch',\n",
    "               'kitchen_dishwasher', 'livingroom_lightswitch', 'foyer_closet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:12.455807Z",
     "start_time": "2019-11-15T16:08:12.382010Z"
    }
   },
   "outputs": [],
   "source": [
    "%run -i determineMeanMedian.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:12.464130Z",
     "start_time": "2019-11-15T16:08:12.459623Z"
    }
   },
   "outputs": [],
   "source": [
    "#allMedianValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:12.880220Z",
     "start_time": "2019-11-15T16:08:12.467899Z"
    }
   },
   "outputs": [],
   "source": [
    "%run -i cleanseOutliers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:12.891020Z",
     "start_time": "2019-11-15T16:08:12.885814Z"
    }
   },
   "outputs": [],
   "source": [
    "#ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:12.903571Z",
     "start_time": "2019-11-15T16:08:12.896011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2697"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:12.951639Z",
     "start_time": "2019-11-15T16:08:12.906121Z"
    }
   },
   "outputs": [],
   "source": [
    "ds.to_csv(PATH + '/intermediate_datasets/S1SubActivities_temporalFeaturesCLEANSED.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Subactivity Visualisation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Bathroom Sickfaucet - Cold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Kitchen Laundry Dryer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct90.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Study Lightswitch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct92.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <img src=\"images/subAct92_cleansed.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Bathroom Shower Faucet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct93.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <img src=\"images/subAct93_cleansed.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Bathroom Exhaust Fan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct96.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Kitchen Garbage Disposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct98.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Bathroom Toiletflush"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Text - ADD LINE SEGMENT CHART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct100.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <img src=\"images/subAct100_cleansed.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> \n",
    "\n",
    "**ADD line segment chart**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Bathroom Lightswitch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct101.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Foyer Lightswitch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct104.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Kitchen Lightswitch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct105.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <img src=\"images/subAct105_cleansed.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Kitchen Burner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct106.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Livingroom Lightswitch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct107.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <img src=\"images/subAct107_cleansed.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Bedroom Lightswitch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct108.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Kitchen Coffee Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct119.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Kitchen Drawer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct125.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <img src=\"images/subAct125_cleansed.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Kitchen Refrigerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct126.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Kitchen Oven"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct129.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Bathroom Door"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct130.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <img src=\"images/subAct130_cleansed.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Kitchen Toaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct131.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Kitchen Cabinet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct132.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Kitchen Freezer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct137.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <img src=\"images/subAct137_cleansed.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Bedroom Jewelrybox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "DROPPED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct139.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Foyer Door"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "<img src=\"images/subAct140.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "<i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Kitchen Door - CORRECT TYPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct141.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <img src=\"images/subAct141_cleansed.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Kitchen Washingmachine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct142.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Kitchen Microwave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The kit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct143.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <img src=\"images/subAct143_cleansed.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Kitchen Cereal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "DROPPED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "<img src=\"images/subAct145.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "<i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Bedroom Drawer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T11:09:02.521879Z",
     "start_time": "2019-11-02T11:09:02.504276Z"
    },
    "hidden": true
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/subAct146.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <img src=\"images/subAct146_cleansed.png\" title=\"Test Title\" alt=\"Alt text\" />\n",
    "    <i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis & Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determination of the most 'effective' data structure - NOT HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key finding = data structure most amenable...**\n",
    "\n",
    "- Driven by two main concepts (main?)\n",
    "- Driven by two competing concepts (competing?)\n",
    "\n",
    "<center>\n",
    "<img src=\"images/huangC.png\" title=\"Test Title\" alt=\"Alt text\" width=\"400\" height=\"400\" />\n",
    "<i> MENTION THIS FROM Huang et al. </i> <br>\n",
    "</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:48.482037Z",
     "start_time": "2019-11-15T16:08:48.463519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "%run -i Packages.py\n",
    "%matplotlib inline\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:50.345175Z",
     "start_time": "2019-11-15T16:08:48.486033Z"
    }
   },
   "outputs": [],
   "source": [
    "%run -i PlotlyPackages.py\n",
    "ds = pd.read_csv('S1SubActivities_temporalFeaturesCLEANSED.csv', index_col = None)\n",
    "ds.start = pd.to_datetime(ds.start, format='%Y-%m-%d %H:%M:%S')\n",
    "ds.end = pd.to_datetime(ds.end, format='%Y-%m-%d %H:%M:%S')\n",
    "ds = ds.sort_values('start')\n",
    "ds.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:50.376049Z",
     "start_time": "2019-11-15T16:08:50.352435Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subActNum</th>\n",
       "      <th>subAct</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>dayNumeric</th>\n",
       "      <th>DAY</th>\n",
       "      <th>WDWE</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>durationSec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>bathroom_cabinet</td>\n",
       "      <td>2003-03-27 06:43:40</td>\n",
       "      <td>2003-03-27 06:43:44</td>\n",
       "      <td>3</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>bathroom_toiletflush</td>\n",
       "      <td>2003-03-27 06:44:06</td>\n",
       "      <td>2003-03-27 06:44:07</td>\n",
       "      <td>3</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>bathroom_lightswitch</td>\n",
       "      <td>2003-03-27 06:44:20</td>\n",
       "      <td>2003-03-27 07:46:35</td>\n",
       "      <td>3</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "      <td>3735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>bathroom_medicinecabinet</td>\n",
       "      <td>2003-03-27 06:44:35</td>\n",
       "      <td>2003-03-27 06:44:49</td>\n",
       "      <td>3</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>bathroom_medicinecabinet</td>\n",
       "      <td>2003-03-27 06:44:36</td>\n",
       "      <td>2003-03-27 06:44:49</td>\n",
       "      <td>3</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subActNum                    subAct               start  \\\n",
       "0         67          bathroom_cabinet 2003-03-27 06:43:40   \n",
       "1        100      bathroom_toiletflush 2003-03-27 06:44:06   \n",
       "2        101      bathroom_lightswitch 2003-03-27 06:44:20   \n",
       "3         57  bathroom_medicinecabinet 2003-03-27 06:44:35   \n",
       "4         57  bathroom_medicinecabinet 2003-03-27 06:44:36   \n",
       "\n",
       "                  end  dayNumeric  DAY WDWE  HOUR  durationSec  \n",
       "0 2003-03-27 06:43:44           3  Thu   WD     6            4  \n",
       "1 2003-03-27 06:44:07           3  Thu   WD     6            1  \n",
       "2 2003-03-27 07:46:35           3  Thu   WD     6         3735  \n",
       "3 2003-03-27 06:44:49           3  Thu   WD     6           14  \n",
       "4 2003-03-27 06:44:49           3  Thu   WD     6           13  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head() # REALLY RE-IMPORT???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MENTION SEGMETNATION HERE OF 3 PARTS OF DAY\n",
    "- Morning\n",
    "- Afternoon\n",
    "- Evening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADD DAY SEGMENTATION SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal segmentation consideration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Statement\n",
    "**If start EVENTA between X and Y on a WD/WE the PR that I will start EVENTB within Z minutes is Q.**\n",
    "\n",
    ">_If I switch on the bathroom light switch between 6am and 7am on a weekday, the probability that I will use my razor is X._\n",
    "\n",
    "- Relationships\n",
    "\n",
    "- Intersection\n",
    "<pre>\n",
    "|----EventA----|  <br>\n",
    "            |---EventB---|   \n",
    "</pre>\n",
    "\n",
    "- Separate\n",
    "<pre>\n",
    "|----EventA----|  <br>\n",
    "                    |---EventB---|   \n",
    "</pre>\n",
    "\n",
    "- Enclosed\n",
    "<pre>\n",
    "|----------EventA----------|  <br>\n",
    "           |---EventB---|   \n",
    "</pre>\n",
    "\n",
    "- Equal\n",
    "<pre>\n",
    "       |---EventA---|  <br>\n",
    "       |---EventB---|   \n",
    "</pre>\n",
    "\n",
    "---\n",
    "- Pr(EventA delta eventB)\n",
    "\n",
    "- Delta Negative\n",
    "<pre>\n",
    "|----EventA----|  <br>\n",
    "                -Gap- <br>\n",
    "                     |---EventB---|   \n",
    "</pre>\n",
    "\n",
    "- Delta Positive\n",
    "<pre>\n",
    "|------EventA------|  <br>\n",
    "            -Union-   <br>\n",
    "            |---EventB---|   \n",
    "</pre>\n",
    "\n",
    "- Delta Zero\n",
    "<pre>\n",
    "|--EventA--|  <br>\n",
    "\n",
    "           |------EventB------|   \n",
    "</pre>\n",
    "\n",
    "- Equal Start\n",
    "<pre>\n",
    "|--EventA--|  <br>\n",
    "\n",
    "|------EventB------|   \n",
    "</pre>\n",
    "\n",
    "**Input A:** S1SubActivities_preprocessed.csv\n",
    "\n",
    "| Event    | EventStart | EventEnd   |        \n",
    "|:--------:|:--------:  | :--------: |        \n",
    "| 100      | dateTime   | dateTime   |        \n",
    "| 101      | dateTime   | dateTime   |        \n",
    "| 104      | dateTime   | dateTime   |  \n",
    "| 105      | dateTime   | dateTime   |  \n",
    "\n",
    "**Input B:** dsCombin2n\n",
    "\n",
    "| EventA   | EventB  | \n",
    "|:--------:|:-------:| \n",
    "| 100      | 101     | \n",
    "| 100      | 104     | \n",
    "| 100      | 105     | \n",
    "| 100      | 106     | \n",
    "\n",
    "**Function:** def id_delta(InputA, InputB)  <br>\n",
    "**Output:**\n",
    "\n",
    "| EventA   | EventB   |  Ev.A Start | Ev.A End | Ev.B Start | Ev.B End | Delta    | Descriptor |\n",
    "|:--------:|:--------:| :--------:  | :------: |:--------:  | :------: | :------: | :------:   |\n",
    "| 100      | 101      |  dateTime   | dateTime | dateTime   | dateTime | -4       | Gap        |\n",
    "| 100      | 104      |  dateTime   | dateTime | dateTime   | dateTime | 92       | Union      |\n",
    "| 100      | 105      |  dateTime   | dateTime | dateTime   | dateTime | 0        | Zero       | \n",
    "| 100      | 106      |  dateTime   | dateTime | dateTime   | dateTime | ???      | EqualStart | \n",
    "\n",
    "**Function:** def add_temporalFeatures(): <br>\n",
    "**Output:**\n",
    "\n",
    "| EventA| EventB| Ev.A Start| Ev.A End| Ev.B Start|Ev.B End|Delta   | Descriptor | WendWday|Hour  |TimeofDay|\n",
    "|:-----:|:-----:|:--------: | :------:|:--------: |:------:|:------:| :------:   | :------:|:----:|:------: |\n",
    "| 100   | 101   | dateTime  | dateTime| dateTime  |dateTime|-4      | Gap        | weekday | 6:00 |6Till8   |\n",
    "| 100   | 104   | dateTime  | dateTime| dateTime  |dateTime|92      | Union      | weekend |12:00 |12Till14 |\n",
    "| 100   | 105   | dateTime  | dateTime| dateTime  |dateTime|0       | Zero       | weekday |15:00 |15Till17 |\n",
    "| 100   | 106   | dateTime  | dateTime| dateTime  |dateTime|???     | EqualStart | weekday |15:00 |15Till17 |\n",
    "\n",
    "- def id_delta(InputA, InputB)\n",
    "\n",
    "* WHERE event A is followed/ union/ gap (first )  by event B\n",
    "* IF (event A end < event B start)\n",
    "* SUM (event B start - event A end) = delta\n",
    "* Add delta attribute to df\n",
    "* RETURN df\n",
    "\n",
    "---\n",
    "\n",
    "1. Equal Start\n",
    "2. Delta positive (the highest)\n",
    "3. Delta Zero (the first)\n",
    "4. Delta Negative (closest to zero)\n",
    "\n",
    "\n",
    "And nearest 5 \n",
    "\n",
    "The dataset <br>\n",
    "@SANKEY\n",
    "The sankey diagrams show the sequences such that certain activities (NOT requiring electricity) mostly [always?] come before those that require electricity. In other words, 'energy poor' activities often act of preparative in the lead up to 'energy intensive' activities. The Sankey can show this by looking at the 'terminal events'.\n",
    "\n",
    "- Discuss the THREE PHASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three-phase ds segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical analysis of three phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:51.200416Z",
     "start_time": "2019-11-15T16:08:51.196767Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://iotproject-s3644119.notebooks.azure.com/j/notebooks/05.%20S1a%20SubAct%20Duration%20Plots-Copy1.ipynb\n",
    "# subActRows = []\n",
    "\n",
    "# for subActName in subActNames:\n",
    "#     dsNew = ds[ds.subAct == subActName]\n",
    "#     dsNew = ds[ds.subAct == subActName]\n",
    "#     count = dsNew.durationSec.count()\n",
    "#     median = dsNew.durationSec.median()\n",
    "#     mean = dsNew.durationSec.mean() \n",
    "#     std = dsNew.durationSec.std()\n",
    "#     #outliers = detect_outlier(dsNew['durationSec'])\n",
    "    \n",
    "#     column = {'SubAct': subActName,'Count': count,'Median': median, 'Mean': mean, 'Std': std}\n",
    "#     subActRows.append(column)\n",
    "\n",
    "# allMedianValues = pd.DataFrame(subActRows, index=None, \n",
    "#                             columns=['SubAct', 'Count', 'Median', 'Mean', \"Std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:52.039317Z",
     "start_time": "2019-11-15T16:08:52.022273Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "def id_delta(events, n=1, delta_threshold=dt.timedelta(-99)):\n",
    "    nns = []\n",
    "    for row in events.itertuples():\n",
    "        #print(row)\n",
    "        start_time = getattr(row, 'start')\n",
    "        end_time = getattr(row, 'end')\n",
    "        subActNum = getattr(row, 'subActNum')\n",
    "        row_index = getattr(row, 'Index')\n",
    "        \n",
    "        nn = events[(events.start >= start_time) & \n",
    "                    (events.index != row_index) & \n",
    "                    ((start_time - events.start) > delta_threshold)][:n]\n",
    "        #print(len(nn))\n",
    "        ordered = pd.DataFrame()\n",
    "        ordered['Dummy'] = nn['subActNum']\n",
    "        ordered['EventA'] = subActNum\n",
    "        ordered['EventB'] = nn['subActNum']\n",
    "        ordered['EvA_Start'] = start_time\n",
    "        ordered['EvB_Start'] = nn['start']\n",
    "        ordered['EvA_End'] = end_time\n",
    "        ordered['EvB_End'] = nn['end']\n",
    "        del ordered['Dummy']\n",
    "        nns.append(ordered)\n",
    "  \n",
    "    #print(nns)\n",
    "    result = pd.concat(nns)\n",
    "    result['Delta'] = np.where(result['EvA_Start']==result['EvB_Start'], \n",
    "                               0,\n",
    "                               (result['EvB_Start'] - result['EvA_Start']))\n",
    "    result['Delta'] = result['Delta'].dt.total_seconds()\n",
    "    return result\n",
    "\n",
    "#ds_1n_25s['Delta'].dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:08:52.052368Z",
     "start_time": "2019-11-15T16:08:52.043796Z"
    }
   },
   "outputs": [],
   "source": [
    "%run -i add_DAY_WDWE_phaseII.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:09:25.876272Z",
     "start_time": "2019-11-15T16:08:52.057827Z"
    }
   },
   "outputs": [],
   "source": [
    "ds_1n_60s = id_delta(ds, 1, dt.timedelta(0,-60))    # Creating DS with specified time and n \n",
    "ds_1n_60s = add_DAY_WDWE_phaseII(ds_1n_60s)         # Adding temporal features\n",
    "# SHOULD I LIMIT TO 60 SECONDS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:09:25.905019Z",
     "start_time": "2019-11-15T16:09:25.882261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventA</th>\n",
       "      <th>EventB</th>\n",
       "      <th>EvA_Start</th>\n",
       "      <th>EvB_Start</th>\n",
       "      <th>EvA_End</th>\n",
       "      <th>EvB_End</th>\n",
       "      <th>Delta</th>\n",
       "      <th>DAY</th>\n",
       "      <th>WDWE</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>100</td>\n",
       "      <td>2003-03-27 06:43:40</td>\n",
       "      <td>2003-03-27 06:44:06</td>\n",
       "      <td>2003-03-27 06:43:44</td>\n",
       "      <td>2003-03-27 06:44:07</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>2003-03-27 06:44:06</td>\n",
       "      <td>2003-03-27 06:44:20</td>\n",
       "      <td>2003-03-27 06:44:07</td>\n",
       "      <td>2003-03-27 07:46:35</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>57</td>\n",
       "      <td>2003-03-27 06:44:20</td>\n",
       "      <td>2003-03-27 06:44:35</td>\n",
       "      <td>2003-03-27 07:46:35</td>\n",
       "      <td>2003-03-27 06:44:49</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>2003-03-27 06:44:35</td>\n",
       "      <td>2003-03-27 06:44:36</td>\n",
       "      <td>2003-03-27 06:44:49</td>\n",
       "      <td>2003-03-27 06:44:49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>67</td>\n",
       "      <td>2003-03-27 06:44:36</td>\n",
       "      <td>2003-03-27 06:44:49</td>\n",
       "      <td>2003-03-27 06:44:49</td>\n",
       "      <td>2003-03-27 06:44:57</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>67</td>\n",
       "      <td>82</td>\n",
       "      <td>2003-03-27 06:44:49</td>\n",
       "      <td>2003-03-27 06:45:45</td>\n",
       "      <td>2003-03-27 06:44:57</td>\n",
       "      <td>2003-03-27 06:45:49</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>82</td>\n",
       "      <td>146</td>\n",
       "      <td>2003-03-27 06:45:45</td>\n",
       "      <td>2003-03-27 06:46:12</td>\n",
       "      <td>2003-03-27 06:45:49</td>\n",
       "      <td>2003-03-27 06:46:21</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>143</td>\n",
       "      <td>132</td>\n",
       "      <td>2003-03-27 06:54:09</td>\n",
       "      <td>2003-03-27 06:54:16</td>\n",
       "      <td>2003-03-27 06:54:15</td>\n",
       "      <td>2003-03-27 06:54:20</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>141</td>\n",
       "      <td>93</td>\n",
       "      <td>2003-03-27 07:04:55</td>\n",
       "      <td>2003-03-27 07:05:22</td>\n",
       "      <td>2003-03-27 07:04:58</td>\n",
       "      <td>2003-03-27 07:05:25</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>93</td>\n",
       "      <td>132</td>\n",
       "      <td>2003-03-27 07:05:22</td>\n",
       "      <td>2003-03-27 07:05:39</td>\n",
       "      <td>2003-03-27 07:05:25</td>\n",
       "      <td>2003-03-27 07:05:58</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventA  EventB           EvA_Start           EvB_Start             EvA_End  \\\n",
       "0      67     100 2003-03-27 06:43:40 2003-03-27 06:44:06 2003-03-27 06:43:44   \n",
       "1     100     101 2003-03-27 06:44:06 2003-03-27 06:44:20 2003-03-27 06:44:07   \n",
       "2     101      57 2003-03-27 06:44:20 2003-03-27 06:44:35 2003-03-27 07:46:35   \n",
       "3      57      57 2003-03-27 06:44:35 2003-03-27 06:44:36 2003-03-27 06:44:49   \n",
       "4      57      67 2003-03-27 06:44:36 2003-03-27 06:44:49 2003-03-27 06:44:49   \n",
       "5      67      82 2003-03-27 06:44:49 2003-03-27 06:45:45 2003-03-27 06:44:57   \n",
       "6      82     146 2003-03-27 06:45:45 2003-03-27 06:46:12 2003-03-27 06:45:49   \n",
       "7     143     132 2003-03-27 06:54:09 2003-03-27 06:54:16 2003-03-27 06:54:15   \n",
       "8     141      93 2003-03-27 07:04:55 2003-03-27 07:05:22 2003-03-27 07:04:58   \n",
       "9      93     132 2003-03-27 07:05:22 2003-03-27 07:05:39 2003-03-27 07:05:25   \n",
       "\n",
       "              EvB_End  Delta  DAY WDWE  Hour  \n",
       "0 2003-03-27 06:44:07   26.0  Thu   WD     6  \n",
       "1 2003-03-27 07:46:35   14.0  Thu   WD     6  \n",
       "2 2003-03-27 06:44:49   15.0  Thu   WD     6  \n",
       "3 2003-03-27 06:44:49    1.0  Thu   WD     6  \n",
       "4 2003-03-27 06:44:57   13.0  Thu   WD     6  \n",
       "5 2003-03-27 06:45:49   56.0  Thu   WD     6  \n",
       "6 2003-03-27 06:46:21   27.0  Thu   WD     6  \n",
       "7 2003-03-27 06:54:20    7.0  Thu   WD     6  \n",
       "8 2003-03-27 07:05:25   27.0  Thu   WD     7  \n",
       "9 2003-03-27 07:05:58   17.0  Thu   WD     7  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_1n_60s.head(n=10) # MENTION THAT OWING TO TIME CONSTAINTS, COULD NOT DO TEMPORAL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:09:55.499203Z",
     "start_time": "2019-11-15T16:09:25.907574Z"
    }
   },
   "outputs": [],
   "source": [
    "ds_10n_60s = id_delta(ds, 10, dt.timedelta(0,-60))    # Creating DS with specified time and n \n",
    "ds_10n_60s = add_DAY_WDWE_phaseII(ds_10n_60s)         # Adding temporal features\n",
    "# SHOULD I LIMIT TO 60 SECONDS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:09:55.548886Z",
     "start_time": "2019-11-15T16:09:55.505548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventA</th>\n",
       "      <th>EventB</th>\n",
       "      <th>EvA_Start</th>\n",
       "      <th>EvB_Start</th>\n",
       "      <th>EvA_End</th>\n",
       "      <th>EvB_End</th>\n",
       "      <th>Delta</th>\n",
       "      <th>DAY</th>\n",
       "      <th>WDWE</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>100</td>\n",
       "      <td>2003-03-27 06:43:40</td>\n",
       "      <td>2003-03-27 06:44:06</td>\n",
       "      <td>2003-03-27 06:43:44</td>\n",
       "      <td>2003-03-27 06:44:07</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>101</td>\n",
       "      <td>2003-03-27 06:43:40</td>\n",
       "      <td>2003-03-27 06:44:20</td>\n",
       "      <td>2003-03-27 06:43:44</td>\n",
       "      <td>2003-03-27 07:46:35</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>57</td>\n",
       "      <td>2003-03-27 06:43:40</td>\n",
       "      <td>2003-03-27 06:44:35</td>\n",
       "      <td>2003-03-27 06:43:44</td>\n",
       "      <td>2003-03-27 06:44:49</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67</td>\n",
       "      <td>57</td>\n",
       "      <td>2003-03-27 06:43:40</td>\n",
       "      <td>2003-03-27 06:44:36</td>\n",
       "      <td>2003-03-27 06:43:44</td>\n",
       "      <td>2003-03-27 06:44:49</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>2003-03-27 06:44:06</td>\n",
       "      <td>2003-03-27 06:44:20</td>\n",
       "      <td>2003-03-27 06:44:07</td>\n",
       "      <td>2003-03-27 07:46:35</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>57</td>\n",
       "      <td>2003-03-27 06:44:06</td>\n",
       "      <td>2003-03-27 06:44:35</td>\n",
       "      <td>2003-03-27 06:44:07</td>\n",
       "      <td>2003-03-27 06:44:49</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>57</td>\n",
       "      <td>2003-03-27 06:44:06</td>\n",
       "      <td>2003-03-27 06:44:36</td>\n",
       "      <td>2003-03-27 06:44:07</td>\n",
       "      <td>2003-03-27 06:44:49</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>67</td>\n",
       "      <td>2003-03-27 06:44:06</td>\n",
       "      <td>2003-03-27 06:44:49</td>\n",
       "      <td>2003-03-27 06:44:07</td>\n",
       "      <td>2003-03-27 06:44:57</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>101</td>\n",
       "      <td>57</td>\n",
       "      <td>2003-03-27 06:44:20</td>\n",
       "      <td>2003-03-27 06:44:35</td>\n",
       "      <td>2003-03-27 07:46:35</td>\n",
       "      <td>2003-03-27 06:44:49</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>101</td>\n",
       "      <td>57</td>\n",
       "      <td>2003-03-27 06:44:20</td>\n",
       "      <td>2003-03-27 06:44:36</td>\n",
       "      <td>2003-03-27 07:46:35</td>\n",
       "      <td>2003-03-27 06:44:49</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventA  EventB           EvA_Start           EvB_Start             EvA_End  \\\n",
       "0      67     100 2003-03-27 06:43:40 2003-03-27 06:44:06 2003-03-27 06:43:44   \n",
       "1      67     101 2003-03-27 06:43:40 2003-03-27 06:44:20 2003-03-27 06:43:44   \n",
       "2      67      57 2003-03-27 06:43:40 2003-03-27 06:44:35 2003-03-27 06:43:44   \n",
       "3      67      57 2003-03-27 06:43:40 2003-03-27 06:44:36 2003-03-27 06:43:44   \n",
       "4     100     101 2003-03-27 06:44:06 2003-03-27 06:44:20 2003-03-27 06:44:07   \n",
       "5     100      57 2003-03-27 06:44:06 2003-03-27 06:44:35 2003-03-27 06:44:07   \n",
       "6     100      57 2003-03-27 06:44:06 2003-03-27 06:44:36 2003-03-27 06:44:07   \n",
       "7     100      67 2003-03-27 06:44:06 2003-03-27 06:44:49 2003-03-27 06:44:07   \n",
       "8     101      57 2003-03-27 06:44:20 2003-03-27 06:44:35 2003-03-27 07:46:35   \n",
       "9     101      57 2003-03-27 06:44:20 2003-03-27 06:44:36 2003-03-27 07:46:35   \n",
       "\n",
       "              EvB_End  Delta  DAY WDWE  Hour  \n",
       "0 2003-03-27 06:44:07   26.0  Thu   WD     6  \n",
       "1 2003-03-27 07:46:35   40.0  Thu   WD     6  \n",
       "2 2003-03-27 06:44:49   55.0  Thu   WD     6  \n",
       "3 2003-03-27 06:44:49   56.0  Thu   WD     6  \n",
       "4 2003-03-27 07:46:35   14.0  Thu   WD     6  \n",
       "5 2003-03-27 06:44:49   29.0  Thu   WD     6  \n",
       "6 2003-03-27 06:44:49   30.0  Thu   WD     6  \n",
       "7 2003-03-27 06:44:57   43.0  Thu   WD     6  \n",
       "8 2003-03-27 06:44:49   15.0  Thu   WD     6  \n",
       "9 2003-03-27 06:44:49   16.0  Thu   WD     6  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_10n_60s.head(n=10) # MENTION THAT OWING TO TIME CONSTAINTS, COULD NOT DO TEMPORAL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:09:55.565772Z",
     "start_time": "2019-11-15T16:09:55.554876Z"
    }
   },
   "outputs": [],
   "source": [
    "# SAVE THE CSV AND CB (below)!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sankey Diagrams - Qualitative Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:10:04.659576Z",
     "start_time": "2019-11-15T16:10:04.630656Z"
    }
   },
   "outputs": [],
   "source": [
    "def genSankey(df,cat_cols=[],value_cols='',title='Sankey Diagram'):\n",
    "    labelList = []\n",
    "    colorNumList = []\n",
    "    for catCol in cat_cols:\n",
    "        labelListTemp =  list(set(df[catCol].values))\n",
    "        colorNumList.append(len(labelListTemp))\n",
    "        labelList = labelList + labelListTemp\n",
    "        \n",
    "    labelList = list(dict.fromkeys(labelList))\n",
    "        \n",
    "    ds = pd.read_csv(PATH + '/intermediate_datasets/S1Sensors_preprocessed.csv', \n",
    "                     index_col = 'subActNum')\n",
    "    \n",
    "    colorList = []\n",
    "    for subActNum in labelList:\n",
    "        if ds.loc[subActNum, 'reqEnergy']:\n",
    "            colorList.append(\"red\")\n",
    "        else:\n",
    "            colorList.append(\"blue\")\n",
    "    \n",
    "    newLabelList = []\n",
    "    for subActNum in labelList:\n",
    "        newLabelList.append(ds.loc[subActNum, 'room'] + \" - \" + ds.loc[subActNum, 'activity'])\n",
    "    \n",
    "    # transform df into a source-target pair\n",
    "    for i in range(len(cat_cols)-1):\n",
    "        if i==0:\n",
    "            sourceTargetDf = df[[cat_cols[i],cat_cols[i+1],value_cols]]\n",
    "            sourceTargetDf.columns = ['source','target','count']\n",
    "        else:\n",
    "            tempDf = df[[cat_cols[i],cat_cols[i+1],value_cols]]\n",
    "            tempDf.columns = ['source','target','count']\n",
    "            sourceTargetDf = pd.concat([sourceTargetDf,tempDf])\n",
    "        sourceTargetDf = sourceTargetDf.groupby(['source','target']).agg({'count':'sum'}).reset_index()\n",
    "        \n",
    "    # add index for source-target pair\n",
    "    sourceTargetDf['sourceID'] = sourceTargetDf['source'].apply(lambda x: labelList.index(x))\n",
    "    sourceTargetDf['targetID'] = sourceTargetDf['target'].apply(lambda x: labelList.index(x))\n",
    "    \n",
    "    labelList = newLabelList\n",
    "    \n",
    "    # creating the sankey diagram\n",
    "    data = dict(type='sankey', \n",
    "                node = dict(pad = 15, thickness = 20, line = dict(color = \"black\", width = 0.5),\n",
    "                            label = labelList,\n",
    "                            color = colorList),\n",
    "                link = dict(source = sourceTargetDf['sourceID'],\n",
    "                            target = sourceTargetDf['targetID'],\n",
    "                            value = sourceTargetDf['count']))\n",
    "    \n",
    "    layout =  dict(title = title, font = dict(size = 10))\n",
    "    fig = dict(data=[data], layout=layout)\n",
    "    \n",
    "    return fig\n",
    "# COLOUR - https://stackoverflow.com/questions/55862005/plotly-sankey-diagram-group-label-and-color \n",
    "# https://medium.com/plotly/4-interactive-sankey-diagram-made-in-python-3057b9ee8616\n",
    "# https://community.periscopedata.com/t/63nx0x/sankey-diagrams-with-plot-ly-in-periscope\n",
    "# https://medium.com/kenlok/how-to-create-sankey-diagrams-from-dataframes-in-python-e221c1b4d6b0\n",
    "# https://community.periscopedata.com/t/k9s9mg/sankey-plot-ly\n",
    "# https://plot.ly/python/sankey-diagram/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T07:18:41.480589Z",
     "start_time": "2019-11-03T07:18:41.461499Z"
    }
   },
   "outputs": [],
   "source": [
    "#fig = genSankey(ds_1n_25s, cat_cols=['EventA', 'EventB'], value_cols='Delta', title='ds')\n",
    "#py.iplot(go.Figure(fig))\n",
    "# CLEAN UP - SCALING + COLOURS + NUMBERS CONVERTED TO WORDS (or KEY?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:10:21.627885Z",
     "start_time": "2019-11-15T16:10:10.209380Z"
    }
   },
   "outputs": [],
   "source": [
    "wdwe_title = {\"WD\":\"Weekday\", \"WE\":\"Weekend\"}\n",
    "\n",
    "def addPhase(df):    \n",
    "    df['Phase'] = \"Afternoon\"\n",
    "    df.loc[df['Hour'] < 12, 'Phase'] = \"Morning\"\n",
    "    df.loc[df['Hour'] >= 18, 'Phase'] = \"Evening\"\n",
    "\n",
    "def plotASankey(df, wdwe, phase):\n",
    "    df = df[(df.WDWE==wdwe) & (df.Phase==phase)]\n",
    "    fig = genSankey(df, cat_cols=['EventA', 'EventB'], value_cols='Delta', title=wdwe_title[wdwe] + ' ' + \n",
    "                    phase + ' ' + 'ds_1n_60s')\n",
    "    py.plot(go.Figure(fig), filename=wdwe_title[wdwe] + phase + 'ds_1n_60s' + '.html')\n",
    "\n",
    "addPhase(ds_1n_60s)\n",
    "\n",
    "for wdwe in ['WD','WE']:\n",
    "    for phase in ['Morning', 'Afternoon', 'Evening']:\n",
    "        plotASankey(ds_1n_60s, wdwe, phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T07:18:53.811891Z",
     "start_time": "2019-11-03T07:18:53.792292Z"
    }
   },
   "outputs": [],
   "source": [
    "# SEGMENT TIMES 3 for WD and WE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T07:19:09.800625Z",
     "start_time": "2019-11-03T07:18:53.826950Z"
    }
   },
   "outputs": [],
   "source": [
    "wdwe_title = {\"WD\":\"Weekday\", \"WE\":\"Weekend\"}\n",
    "\n",
    "def addPhase(df):    \n",
    "    df['Phase'] = \"Afternoon\"\n",
    "    df.loc[df['Hour'] < 12, 'Phase'] = \"Morning\"\n",
    "    df.loc[df['Hour'] >= 18, 'Phase'] = \"Evening\"\n",
    "\n",
    "def plotASankey(df, wdwe, phase):\n",
    "    df = df[(df.WDWE==wdwe) & (df.Phase==phase)]\n",
    "    fig = genSankey(df, cat_cols=['EventA', 'EventB'], value_cols='Delta', title=wdwe_title[wdwe] + ' ' + \n",
    "                    phase + ' ' + 'ds_10n_60s')\n",
    "    py.plot(go.Figure(fig), filename=wdwe_title[wdwe] + phase + 'ds_10n_60s' + '.html')\n",
    "\n",
    "addPhase(ds_10n_60s)\n",
    "\n",
    "for wdwe in ['WD','WE']:\n",
    "    for phase in ['Morning', 'Afternoon', 'Evening']:\n",
    "        plotASankey(ds_10n_60s, wdwe, phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:15:48.651116Z",
     "start_time": "2019-11-15T16:15:48.642624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"600\"\n",
       "            src=\"WeekdayAfternoonds_1n_60s.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x12435ffd0>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src='WeekdayAfternoonds_1n_60s.html', width=1000, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T16:10:53.713121Z",
     "start_time": "2019-11-15T16:10:53.698507Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"600\"\n",
       "            src=\"WeekdayAfternoonds_1n_60s.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x123c864d0>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src='WeekdayAfternoonds_1n_60s.html', width=1000, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T17:00:49.698967Z",
     "start_time": "2019-11-15T17:00:49.688294Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"600\"\n",
       "            src=\"WeekdayMorningds_1n_60s.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x124391e90>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src='WeekdayMorningds_1n_60s.html', width=1000, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T17:01:00.628947Z",
     "start_time": "2019-11-15T17:01:00.607297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"600\"\n",
       "            src=\"WeekdayAfternoonds_1n_60s.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x124aea610>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src='WeekdayAfternoonds_1n_60s.html', width=1000, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T17:06:32.213151Z",
     "start_time": "2019-11-15T17:06:32.202411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"600\"\n",
       "            src=\"WeekdayEveningds_1n_60s.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1245bbfd0>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src='WeekdayEveningds_1n_60s.html', width=1000, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T17:13:04.230572Z",
     "start_time": "2019-11-15T17:13:04.219240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"600\"\n",
       "            src=\"WeekendMorningds_1n_60s.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x123ea9110>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src='WeekendMorningds_1n_60s.html', width=1000, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T17:15:38.149857Z",
     "start_time": "2019-11-15T17:15:38.133422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"600\"\n",
       "            src=\"WeekendAfternoonds_1n_60s.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1245b3ed0>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src='WeekendAfternoonds_1n_60s.html', width=1000, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T17:18:18.085275Z",
     "start_time": "2019-11-15T17:18:18.072786Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"600\"\n",
       "            src=\"WeekendEveningds_1n_60s.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x123c9e390>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src='WeekendEveningds_1n_60s.html', width=1000, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T07:20:15.599407Z",
     "start_time": "2019-11-03T07:20:15.544116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T07:20:16.744338Z",
     "start_time": "2019-11-03T07:20:16.708738Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython import get_ipython;   \n",
    "get_ipython().magic('reset -sf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T07:20:22.229010Z",
     "start_time": "2019-11-03T07:20:17.994678Z"
    }
   },
   "outputs": [],
   "source": [
    "%run -i Packages.py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timestamp Structure with Boolean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing Boolean Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input** `ds = pd.read_csv('S1SubActivities_preprocessed.csv', index_col = None) `\n",
    "**Output** `ds.to_csv('S1SubActivities_timeStampRanges.csv',index=False)`\n",
    "\n",
    "- WHY\n",
    "1. This enables us to calculate the FREQUENCY per hour (which in the end was just used to inform later analysis)\n",
    "\n",
    "**Must convert subActNum FROM dtype `int64` to `string` in order for `pd.get_dummies()` to execute.**\n",
    "\n",
    "**Input** `ds = pd.read_csv('S1SubActivities_timeRangeMelt.csv', index_col = None)`\n",
    "**Output** `ds.to_csv('S1SubActivities_timeRangeBoolean_DuplicateIndex.csv',index='duration')` <br>\n",
    "**Output** `ds.to_csv('S1SubActivities_timeRangeBoolean.csv',index='duration')`\n",
    "\n",
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T07:20:24.961433Z",
     "start_time": "2019-11-03T07:20:24.929398Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = pd.read_csv(PATH + '/intermediate_datasets/S1SubActivities_temporalFeaturesCLEANSED.csv', \n",
    "                 index_col = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T07:21:27.579200Z",
     "start_time": "2019-11-03T07:20:28.059151Z"
    }
   },
   "outputs": [],
   "source": [
    "%run -i test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T07:21:53.663346Z",
     "start_time": "2019-11-03T07:21:53.646461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subActNum</th>\n",
       "      <th>subAct</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>dayNumeric</th>\n",
       "      <th>DAY</th>\n",
       "      <th>WDWE</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>durationSec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>bathroom_cabinet</td>\n",
       "      <td>2003-03-27 06:43:40</td>\n",
       "      <td>2003-03-27 06:43:43</td>\n",
       "      <td>3</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>bathroom_toiletflush</td>\n",
       "      <td>2003-03-27 06:44:06</td>\n",
       "      <td>2003-03-27 06:44:07</td>\n",
       "      <td>3</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>bathroom_lightswitch</td>\n",
       "      <td>2003-03-27 06:44:20</td>\n",
       "      <td>2003-03-27 07:46:34</td>\n",
       "      <td>3</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "      <td>3735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>bathroom_medicinecabinet</td>\n",
       "      <td>2003-03-27 06:44:35</td>\n",
       "      <td>2003-03-27 06:44:48</td>\n",
       "      <td>3</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>bathroom_medicinecabinet</td>\n",
       "      <td>2003-03-27 06:44:36</td>\n",
       "      <td>2003-03-27 06:44:48</td>\n",
       "      <td>3</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subActNum                    subAct                start  \\\n",
       "0         67          bathroom_cabinet  2003-03-27 06:43:40   \n",
       "1        100      bathroom_toiletflush  2003-03-27 06:44:06   \n",
       "2        101      bathroom_lightswitch  2003-03-27 06:44:20   \n",
       "3         57  bathroom_medicinecabinet  2003-03-27 06:44:35   \n",
       "4         57  bathroom_medicinecabinet  2003-03-27 06:44:36   \n",
       "\n",
       "                   end  dayNumeric  DAY WDWE  HOUR  durationSec  \n",
       "0  2003-03-27 06:43:43           3  Thu   WD     6            4  \n",
       "1  2003-03-27 06:44:07           3  Thu   WD     6            2  \n",
       "2  2003-03-27 07:46:34           3  Thu   WD     6         3735  \n",
       "3  2003-03-27 06:44:48           3  Thu   WD     6           14  \n",
       "4  2003-03-27 06:44:48           3  Thu   WD     6           13  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_initial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T07:22:18.686247Z",
     "start_time": "2019-11-03T07:22:18.657701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subActNum</th>\n",
       "      <th>subAct</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>dayNumeric</th>\n",
       "      <th>DAY</th>\n",
       "      <th>WDWE</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>actDuration</th>\n",
       "      <th>timeStampArrayList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>bathroom_cabinet</td>\n",
       "      <td>2003-03-27 06:43:40</td>\n",
       "      <td>2003-03-27 06:43:43</td>\n",
       "      <td>3</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>[2003-03-27 06:43:40, 2003-03-27 06:43:41, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>bathroom_toiletflush</td>\n",
       "      <td>2003-03-27 06:44:06</td>\n",
       "      <td>2003-03-27 06:44:07</td>\n",
       "      <td>3</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[2003-03-27 06:44:06, 2003-03-27 06:44:07]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>bathroom_lightswitch</td>\n",
       "      <td>2003-03-27 06:44:20</td>\n",
       "      <td>2003-03-27 07:46:34</td>\n",
       "      <td>3</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "      <td>3735</td>\n",
       "      <td>[2003-03-27 06:44:20, 2003-03-27 06:44:21, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>bathroom_medicinecabinet</td>\n",
       "      <td>2003-03-27 06:44:35</td>\n",
       "      <td>2003-03-27 06:44:48</td>\n",
       "      <td>3</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>[2003-03-27 06:44:35, 2003-03-27 06:44:36, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>bathroom_medicinecabinet</td>\n",
       "      <td>2003-03-27 06:44:36</td>\n",
       "      <td>2003-03-27 06:44:48</td>\n",
       "      <td>3</td>\n",
       "      <td>Thu</td>\n",
       "      <td>WD</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>[2003-03-27 06:44:36, 2003-03-27 06:44:37, 200...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subActNum                    subAct                start  \\\n",
       "0         67          bathroom_cabinet  2003-03-27 06:43:40   \n",
       "1        100      bathroom_toiletflush  2003-03-27 06:44:06   \n",
       "2        101      bathroom_lightswitch  2003-03-27 06:44:20   \n",
       "3         57  bathroom_medicinecabinet  2003-03-27 06:44:35   \n",
       "4         57  bathroom_medicinecabinet  2003-03-27 06:44:36   \n",
       "\n",
       "                   end  dayNumeric  DAY WDWE  HOUR  actDuration  \\\n",
       "0  2003-03-27 06:43:43           3  Thu   WD     6            4   \n",
       "1  2003-03-27 06:44:07           3  Thu   WD     6            2   \n",
       "2  2003-03-27 07:46:34           3  Thu   WD     6         3735   \n",
       "3  2003-03-27 06:44:48           3  Thu   WD     6           14   \n",
       "4  2003-03-27 06:44:48           3  Thu   WD     6           13   \n",
       "\n",
       "                                  timeStampArrayList  \n",
       "0  [2003-03-27 06:43:40, 2003-03-27 06:43:41, 200...  \n",
       "1         [2003-03-27 06:44:06, 2003-03-27 06:44:07]  \n",
       "2  [2003-03-27 06:44:20, 2003-03-27 06:44:21, 200...  \n",
       "3  [2003-03-27 06:44:35, 2003-03-27 06:44:36, 200...  \n",
       "4  [2003-03-27 06:44:36, 2003-03-27 06:44:37, 200...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_int_one.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T07:22:45.807063Z",
     "start_time": "2019-11-03T07:22:45.779669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subActNum</th>\n",
       "      <th>end</th>\n",
       "      <th>actDuration</th>\n",
       "      <th>timeStampArrayList</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-03-27 06:43:40</th>\n",
       "      <td>67</td>\n",
       "      <td>2003-03-27 06:43:43</td>\n",
       "      <td>4</td>\n",
       "      <td>[2003-03-27 06:43:40, 2003-03-27 06:43:41, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-03-27 06:44:06</th>\n",
       "      <td>100</td>\n",
       "      <td>2003-03-27 06:44:07</td>\n",
       "      <td>2</td>\n",
       "      <td>[2003-03-27 06:44:06, 2003-03-27 06:44:07]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-03-27 06:44:20</th>\n",
       "      <td>101</td>\n",
       "      <td>2003-03-27 07:46:34</td>\n",
       "      <td>3735</td>\n",
       "      <td>[2003-03-27 06:44:20, 2003-03-27 06:44:21, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-03-27 06:44:35</th>\n",
       "      <td>57</td>\n",
       "      <td>2003-03-27 06:44:48</td>\n",
       "      <td>14</td>\n",
       "      <td>[2003-03-27 06:44:35, 2003-03-27 06:44:36, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-03-27 06:44:36</th>\n",
       "      <td>57</td>\n",
       "      <td>2003-03-27 06:44:48</td>\n",
       "      <td>13</td>\n",
       "      <td>[2003-03-27 06:44:36, 2003-03-27 06:44:37, 200...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     subActNum                  end  actDuration  \\\n",
       "start                                                              \n",
       "2003-03-27 06:43:40         67  2003-03-27 06:43:43            4   \n",
       "2003-03-27 06:44:06        100  2003-03-27 06:44:07            2   \n",
       "2003-03-27 06:44:20        101  2003-03-27 07:46:34         3735   \n",
       "2003-03-27 06:44:35         57  2003-03-27 06:44:48           14   \n",
       "2003-03-27 06:44:36         57  2003-03-27 06:44:48           13   \n",
       "\n",
       "                                                    timeStampArrayList  \n",
       "start                                                                   \n",
       "2003-03-27 06:43:40  [2003-03-27 06:43:40, 2003-03-27 06:43:41, 200...  \n",
       "2003-03-27 06:44:06         [2003-03-27 06:44:06, 2003-03-27 06:44:07]  \n",
       "2003-03-27 06:44:20  [2003-03-27 06:44:20, 2003-03-27 06:44:21, 200...  \n",
       "2003-03-27 06:44:35  [2003-03-27 06:44:35, 2003-03-27 06:44:36, 200...  \n",
       "2003-03-27 06:44:36  [2003-03-27 06:44:36, 2003-03-27 06:44:37, 200...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_int_two.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T07:23:08.646609Z",
     "start_time": "2019-11-03T07:23:08.630154Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subActNum</th>\n",
       "      <th>actDuration</th>\n",
       "      <th>timeStampArrayList</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-03-27 06:43:40</th>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "      <td>[2003-03-27 06:43:40, 2003-03-27 06:43:41, 200...</td>\n",
       "      <td>2003-03-27 06:43:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-03-27 06:43:40</th>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "      <td>[2003-03-27 06:43:40, 2003-03-27 06:43:41, 200...</td>\n",
       "      <td>2003-03-27 06:43:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-03-27 06:43:40</th>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "      <td>[2003-03-27 06:43:40, 2003-03-27 06:43:41, 200...</td>\n",
       "      <td>2003-03-27 06:43:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-03-27 06:43:40</th>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "      <td>[2003-03-27 06:43:40, 2003-03-27 06:43:41, 200...</td>\n",
       "      <td>2003-03-27 06:43:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-03-27 06:44:06</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>[2003-03-27 06:44:06, 2003-03-27 06:44:07]</td>\n",
       "      <td>2003-03-27 06:44:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     subActNum  actDuration  \\\n",
       "start                                         \n",
       "2003-03-27 06:43:40         67            4   \n",
       "2003-03-27 06:43:40         67            4   \n",
       "2003-03-27 06:43:40         67            4   \n",
       "2003-03-27 06:43:40         67            4   \n",
       "2003-03-27 06:44:06        100            2   \n",
       "\n",
       "                                                    timeStampArrayList  \\\n",
       "start                                                                    \n",
       "2003-03-27 06:43:40  [2003-03-27 06:43:40, 2003-03-27 06:43:41, 200...   \n",
       "2003-03-27 06:43:40  [2003-03-27 06:43:40, 2003-03-27 06:43:41, 200...   \n",
       "2003-03-27 06:43:40  [2003-03-27 06:43:40, 2003-03-27 06:43:41, 200...   \n",
       "2003-03-27 06:43:40  [2003-03-27 06:43:40, 2003-03-27 06:43:41, 200...   \n",
       "2003-03-27 06:44:06         [2003-03-27 06:44:06, 2003-03-27 06:44:07]   \n",
       "\n",
       "                               duration  \n",
       "start                                    \n",
       "2003-03-27 06:43:40 2003-03-27 06:43:40  \n",
       "2003-03-27 06:43:40 2003-03-27 06:43:41  \n",
       "2003-03-27 06:43:40 2003-03-27 06:43:42  \n",
       "2003-03-27 06:43:40 2003-03-27 06:43:43  \n",
       "2003-03-27 06:44:06 2003-03-27 06:44:06  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_int_three.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T07:23:32.210153Z",
     "start_time": "2019-11-03T07:23:32.013696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subActNum</th>\n",
       "      <th>actDuration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-03-27 06:43:40</th>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-03-27 06:43:41</th>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-03-27 06:43:42</th>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-03-27 06:43:43</th>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-03-27 06:44:06</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     subActNum  actDuration\n",
       "duration                                   \n",
       "2003-03-27 06:43:40         67            4\n",
       "2003-03-27 06:43:41         67            4\n",
       "2003-03-27 06:43:42         67            4\n",
       "2003-03-27 06:43:43         67            4\n",
       "2003-03-27 06:44:06        100            2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_int_four.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T07:24:20.043964Z",
     "start_time": "2019-11-03T07:24:19.824331Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4c17bfda82cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ds_final' is not defined"
     ]
    }
   ],
   "source": [
    "ds_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T06:13:53.173967Z",
     "start_time": "2019-11-03T06:13:53.098400Z"
    }
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `len(ds)` = 3085839\n",
    "*  (16 * 24 * 60 * 60) < len(ds) = This shows that their are duplicate INDEX values - this is GOOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-03T07:17:31.063Z"
    }
   },
   "outputs": [],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-03T07:17:31.071Z"
    }
   },
   "outputs": [],
   "source": [
    "16 * 24 * 60 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T07:24:45.670286Z",
     "start_time": "2019-11-03T07:24:44.401237Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = ds.groupby(['duration']).agg('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T07:25:07.457560Z",
     "start_time": "2019-11-03T07:25:07.306349Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = ds.dropna(how = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T07:28:42.476424Z",
     "start_time": "2019-11-03T07:28:42.457870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297624"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T07:25:30.016802Z",
     "start_time": "2019-11-03T07:25:29.995436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxValues = ds.max()                              # Checking for max values in df\n",
    "maxValues.max()                                   # The maximum value of max values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Values greater than 1 are attributed to duplication in the original dataset\n",
    "* Values greater than 1 represent only x% - extremely insignificant\n",
    "* All values greater than 1 will be converted to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T07:25:56.962314Z",
     "start_time": "2019-11-03T07:25:52.526422Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = ds.replace(to_replace =[2, 3, 4, 5, 6, 7, 8, \n",
    "                             9, 10, 11, 12, 13, 14, 15, 16], value = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T07:26:21.020967Z",
     "start_time": "2019-11-03T07:26:20.993474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxValues = ds.max()                              # Checking for max values in df\n",
    "maxValues.max()                                   # The maximum value of max values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T07:29:22.433010Z",
     "start_time": "2019-11-03T07:29:08.912968Z"
    }
   },
   "outputs": [],
   "source": [
    "ds.to_csv(PATH + '/intermediate_datasets/S1SubAct_B_s_NoDupes.csv', index='duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-03T07:17:31.678Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "from IPython import get_ipython;\n",
    "get_ipython().magic('reset -sf') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-03T07:17:31.698Z"
    }
   },
   "outputs": [],
   "source": [
    "%run -i Packages.py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collapse S1a SubActivities into Minutes - VALUE OF 60!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why?\n",
    "\n",
    "**Input** `ds = pd.read_csv('S1SubActivities_timeRangeBoolean.csv', index_col = 'duration')` <br>\n",
    "**Input pt II** `ds.index = pd.to_datetime(ds.index)`\n",
    "\n",
    "---\n",
    "\n",
    "**Example preprocessed output:**\n",
    "\n",
    "**ADD DIM**\n",
    "\n",
    "idx (duration)      | subActNum_100 | subActNum_101 | subActNum_104 | subActNum_105 | subActNum_106 |  \n",
    "----------          | ---------     | ----------    | ---------     | ---------     | ---------     |\n",
    "2003-03-27 06:43:00 | 0.0           | 0.0           | 0.0           | 0.0           | 0.0           |\n",
    "2003-03-27 06:44:00 | 1.0           | 1.0           | 0.0           | 0.0           | 0.0           |\n",
    "2003-03-27 06:45:00 | 1.0           | 1.0           | 0.0           | 0.0           | 0.0           |\n",
    "2003-03-27 06:46:00 | 1.0           | 1.0           | 0.0           | 0.0           | 0.0           |\n",
    "2003-03-27 06:47:00 | 1.0           | 1.0           | 0.0           | 0.0           | 0.0           |\n",
    "\n",
    "---\n",
    "\n",
    "**Output** `ds.to_csv('S1SubActivities_timeRangeBooleanMinutes.csv', index = 'duration')` <br>\n",
    "**Output** `ds.to_csv('S1SubActivities_timeRangeBooleanMinutesDropNA.csv', index = 'duration')`\n",
    "\n",
    "* Use in-built Pandas function\n",
    "* `resample('min').max()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-03T07:17:31.716Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = pd.read_csv('intermediate_datasets/S1SubAct_B_s_NoDupes.csv', index_col = 'duration')\n",
    "#ds.index = pd.to_datetime(ds.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-03T07:17:31.733Z"
    }
   },
   "outputs": [],
   "source": [
    "%run -i script_4_6.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-03T07:17:31.743Z"
    }
   },
   "outputs": [],
   "source": [
    "summary = dsMin.describe()\n",
    "summary = summary.transpose()\n",
    "summary.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-03T07:17:31.755Z"
    }
   },
   "outputs": [],
   "source": [
    "summary = dsHour.describe()\n",
    "summary = summary.transpose()\n",
    "summary.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-03T07:17:31.767Z"
    }
   },
   "outputs": [],
   "source": [
    "dsHourFreqMelt.head(n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-03T07:17:31.786Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def add_DAY_WDWE_phaseX(ds):\n",
    "    dayNumKeyWithDAYDict = pd.Series(['Mon','Tue','Wed','Thu','Fri','Sat','Sun'], ['0','1','2','3','4','5','6']).to_dict()\n",
    "    dayNumKeyWithWDWEDict = pd.Series(['WD','WD','WD','WD','WD','WE','WE'], ['0','1','2','3','4','5','6']).to_dict()\n",
    "    ds.set_index(ds.timeStamp, inplace = True)\n",
    "    ds.insert((len(ds.columns)), \"dayNumeric\", ds.index.dayofweek.astype(str), True)\n",
    "    ds.insert((len(ds.columns)), \"DAY\", ds.index.dayofweek.astype(str), True)\n",
    "    ds.insert((len(ds.columns)), \"WDWE\", ds.index.dayofweek.astype(str), True)\n",
    "    ds = ds.replace({\"DAY\": dayNumKeyWithDAYDict})\n",
    "    ds = ds.replace({\"WDWE\": dayNumKeyWithWDWEDict})\n",
    "    ds.reset_index(drop = True, inplace = True)\n",
    "    ds['HOUR'] = ds['timeStamp'].dt.hour\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-03T07:17:31.814Z"
    }
   },
   "outputs": [],
   "source": [
    "dsHourFreqMelt = add_DAY_WDWE_phaseX(dsHourFreqMelt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-03T07:17:31.826Z"
    }
   },
   "outputs": [],
   "source": [
    "dsHourFreqMelt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-03T07:17:31.846Z"
    }
   },
   "outputs": [],
   "source": [
    "dsHourFreqMelt = dsHourFreqMelt.set_index('timeStamp', drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-03T07:17:31.862Z"
    }
   },
   "outputs": [],
   "source": [
    "dsHourFreqMelt.to_csv('ds_resampled_freq.csv',index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-03T07:17:31.875Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "ds <- read_csv(\"ds_resampled_freq.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-03T07:17:31.888Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "colnames(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-03T07:17:31.904Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "ds$DATE <- date(ds$timeStamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-03T07:17:31.920Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R -u px -w 1000 -h 1000\n",
    "p <- ggplot()\n",
    "p <- p + geom_point(data = ds, aes(x = HOUR, y = freq, colour = DAY))\n",
    "p <- p + facet_wrap(facets = vars(subAct)) + theme(legend.position=\"bottom\")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-03T07:17:31.933Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R -u px -w 1000 -h 1000\n",
    "p <- ggplot()\n",
    "p <- p + geom_point(data = ds, aes(x = HOUR, y = freq, colour = WDWE))\n",
    "p <- p + facet_wrap(facets = vars(subAct)) + theme(legend.position=\"bottom\")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text\n",
    "- Past work ('in the literature survery', which was pulled from a broad range of areas) = no consideration of NON-energy consuming activities in XYZ\n",
    "- First point of difference = in both Event Row Structure and Boolean array structure, energy and non-enery will be considered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addition DS = DS with energy amounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Discuss\n",
    "- Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning using Event Row Structure - Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Using Boolean Array Structure - Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import feature_selection as fs\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv('S1Act_B_m_NoDupes.csv', index_col = \"duration\")\n",
    "ds.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart rapper method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "def plot_imp(best_features, scores, method_name, color):\n",
    "    \n",
    "    df = pd.DataFrame({'features': best_features, \n",
    "                       'importances': scores})\n",
    "    \n",
    "    chart = alt.Chart(df, \n",
    "                      width=500, \n",
    "                      title=method_name + ' Feature Importances'\n",
    "                     ).mark_bar(opacity=0.95, \n",
    "                                color=color).encode(\n",
    "        alt.X('features', title='Feature', sort=None, axis=alt.AxisConfig(labelAngle=45)),\n",
    "        alt.Y('importances', title='Importance')\n",
    "    )\n",
    "    \n",
    "    return chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping all SubActs & Determining Top 5 Features based on mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = []\n",
    "\n",
    "for subAct in poweredSubActs:\n",
    "    print(subAct)\n",
    "    row = {\"Target\":subAct}\n",
    "    \n",
    "    Data = ds.drop(columns = subAct).values\n",
    "    target = ds[subAct]\n",
    "    D_train, D_test, t_train, t_test = train_test_split(Data, \n",
    "                                                    target, \n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=999)\n",
    "    \n",
    "    dt_classifier = DecisionTreeClassifier(max_depth=4,\n",
    "                                       criterion='entropy',\n",
    "                                       random_state = 999)\n",
    "    \n",
    "    dt_classifier.fit(D_train, t_train)\n",
    "    print(dt_classifier.score(D_test, t_test))\n",
    "    \n",
    "    cv_method = RepeatedStratifiedKFold(n_splits = 5, \n",
    "                                    n_repeats = 3, \n",
    "                                    random_state = 999)\n",
    "\n",
    "    dt_classifier = DecisionTreeClassifier(random_state=999)\n",
    "\n",
    "    params_DT = {'criterion': ['gini', 'entropy'],\n",
    "                 'max_depth': [2, 3, 4, 5]}\n",
    "\n",
    "    gs = GridSearchCV(estimator=dt_classifier, \n",
    "                      param_grid=params_DT, \n",
    "                      cv=cv_method,\n",
    "                      verbose=1, \n",
    "                      scoring='accuracy')\n",
    "    \n",
    "    print(gs.fit(Data, target))\n",
    "    print(gs.best_params_)\n",
    "    print(gs.best_score_)\n",
    "    \n",
    "    num_features = 5\n",
    "    fs_fit_mutual_info = fs.SelectKBest(fs.mutual_info_classif, k=num_features)\n",
    "    fs_fit_mutual_info.fit_transform(Data, target)\n",
    "    fs_indices_mutual_info = np.argsort(fs_fit_mutual_info.scores_)[::-1][0:num_features]\n",
    "    best_features_mutual_info = ds.columns[fs_indices_mutual_info].values\n",
    "    print(best_features_mutual_info)\n",
    "    \n",
    "    feature_importances_mutual_info = fs_fit_mutual_info.scores_[fs_indices_mutual_info]\n",
    "    print(feature_importances_mutual_info)\n",
    "    \n",
    "    best_feats = dict(zip(best_features_mutual_info, feature_importances_mutual_info))\n",
    "    row.update(best_feats)\n",
    "    table.append(row)\n",
    "    \n",
    "    plot = plot_imp(subAct, best_features_mutual_info, feature_importances_mutual_info, 'Mutual Information', 'blue')\n",
    "    plot.display()\n",
    "    \n",
    "ds_best_feats = pd.DataFrame(table)\n",
    "ds_best_feats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Using Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mutual information method is a filter feature selection method that looks at the relationship between each descriptive feature and the target feature using the concept of entropy.\n",
    "\n",
    "The code below returns the indices of the 5 features that have the highest mutual information value. As in the F-score method, the wrapper is not used in any way when selecting features using the mutual information method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Mutual_information\n",
    "\n",
    "2019-08-25 Talk about abstracting away methods using %run -i 'script.py'\n",
    "Key Finding It is far more straightforward (efficient) to simply plot all subactivities as attributes and then use boolean structure. This gives an 'out of the box' model that can be fed to a machine learning algorithm with minial pre-processing. That in and un or itself is not such a big deal - more so the accuracy level that is returned, plus the reduced requirement to perform matrice operations and using spatial proximity, temporal proximity.\n",
    "\n",
    "Key finding Using sensor-based technology on items that operate when given energy by the end user (eg opening a door), as compared with JUST looking at subActivities that requires external power.\n",
    "\n",
    "https://bokeh.pydata.org/en/latest/docs/gallery/les_mis.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Antagonistic AI for Power Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 5\n",
    "fs_fit_mutual_info = fs.SelectKBest(fs.mutual_info_classif, k=num_features)\n",
    "fs_fit_mutual_info.fit_transform(Data, target)\n",
    "fs_indices_mutual_info = np.argsort(fs_fit_mutual_info.scores_)[::-1][0:num_features]\n",
    "best_features_mutual_info = ds.columns[fs_indices_mutual_info].values\n",
    "best_features_mutual_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_mutual_info = fs_fit_mutual_info.scores_[fs_indices_mutual_info]\n",
    "feature_importances_mutual_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_imp(best_features_mutual_info, feature_importances_mutual_info, 'Mutual Information', 'blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://iotproject-s3644119.notebooks.azure.com/j/notebooks/05.%20S1a%20SubAct%20Duration%20Plots-Copy1.ipynb \n",
    "- Mention 'phased' approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfIDX = pd.read_csv('S1Act_B_m_NoDupes.csv', index_col = None)\n",
    "# dfIDX.duration = pd.to_datetime(dfIDX.duration, format='%Y-%m-%d %H:%M:%S')\n",
    "# dfIDX.head()\n",
    "# dfIDX['duration']\n",
    "# df['timestamp'] = dfIDX['duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime as dt\n",
    "# def add_DAY_WDWE_phaseII(ds):\n",
    "#     dayNumKeyWithDAYDict = pd.Series(['Mon','Tue','Wed','Thu','Fri','Sat','Sun'], ['0','1','2','3','4','5','6']).to_dict()\n",
    "#     dayNumKeyWithWDWEDict = pd.Series(['WD','WD','WD','WD','WD','WE','WE'], ['0','1','2','3','4','5','6']).to_dict()\n",
    "#     ds.set_index(ds['timestamp'], inplace = True)\n",
    "#     ds.insert((len(ds.columns)), \"DAY\", ds.index.dayofweek.astype(str), True)\n",
    "#     ds.insert((len(ds.columns)), \"WDWE\", ds.index.dayofweek.astype(str), True)\n",
    "#     ds = ds.replace({\"DAY\": dayNumKeyWithDAYDict})\n",
    "#     ds = ds.replace({\"WDWE\": dayNumKeyWithWDWEDict})\n",
    "#     ds.reset_index(drop = True, inplace = True)\n",
    "#     ds['Hour'] = ds['timestamp'].dt.hour\n",
    "#     return ds\n",
    "\n",
    "# df = add_DAY_WDWE_phaseII(df)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Phase'] = \"Afternoon\"\n",
    "# df.loc[df['Hour'] < 9, 'Phase'] = \"Morning\"\n",
    "# df.loc[df['Hour'] >= 17, 'Phase'] = \"Evening\"\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import feature_selection as fs\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime as dt\n",
    "\n",
    "df = pd.read_csv('S1Act_B_m_NoDupes.csv', index_col = \"duration\")\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "df_sensors = pd.read_csv('S1Sensors_preprocessed.csv', index_col = None)\n",
    "df_sensors = df_sensors[df_sensors.reqEnergy]\n",
    "\n",
    "df_costs = pd.read_csv('power_costs.csv', index_col = None)\n",
    "\n",
    "def add_DAY_WDWE_phaseII(ds):\n",
    "    dayNumKeyWithDAYDict = pd.Series(['Mon','Tue','Wed','Thu','Fri','Sat','Sun'], ['0','1','2','3','4','5','6']).to_dict()\n",
    "    dayNumKeyWithWDWEDict = pd.Series(['WD','WD','WD','WD','WD','WE','WE'], ['0','1','2','3','4','5','6']).to_dict()\n",
    "    ds.set_index(ds['timestamp'], inplace = True)\n",
    "    ds.insert((len(ds.columns)), \"DAY\", ds.index.dayofweek.astype(str), True)\n",
    "    ds.insert((len(ds.columns)), \"WDWE\", ds.index.dayofweek.astype(str), True)\n",
    "    ds = ds.replace({\"DAY\": dayNumKeyWithDAYDict})\n",
    "    ds = ds.replace({\"WDWE\": dayNumKeyWithWDWEDict})\n",
    "    ds.reset_index(drop = True, inplace = True)\n",
    "    ds['Hour'] = ds['timestamp'].dt.hour\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assuming everything that is common has been pre-processed by this stage\n",
    "\n",
    "def calc_subAct(dataframe, subAct, wattage, df_costs):\n",
    "    # Duplicate the DF to avoid corrupting it\n",
    "    df = dataframe.copy()\n",
    "    \n",
    "    # First step is to train the classifier\n",
    "    Data = df.drop(columns = subAct).values\n",
    "    target = df[subAct]\n",
    "    D_train, D_test, t_train, t_test = train_test_split(Data, \n",
    "                                                        target, \n",
    "                                                        test_size = 0.3,\n",
    "                                                        random_state=999)\n",
    "    dt_classifier = DecisionTreeClassifier(max_depth=4,\n",
    "                                           criterion='entropy',\n",
    "                                           random_state = 999)\n",
    "    dt_classifier.fit(D_train, t_train)\n",
    "    confidence = dt_classifier.score(D_test, t_test)\n",
    "    df['prediction'] = dt_classifier.predict(Data)\n",
    "    df['intervention'] = (df['prediction'].diff() == -1) & (df[subAct] == 1)\n",
    "    \n",
    "    dfIDX = pd.read_csv('S1Act_B_m_NoDupes.csv', index_col = None)\n",
    "    dfIDX.duration = pd.to_datetime(dfIDX.duration, format='%Y-%m-%d %H:%M:%S')\n",
    "    df['timestamp'] = dfIDX['duration']\n",
    "\n",
    "    df = add_DAY_WDWE_phaseII(df)\n",
    "    df['Phase'] = \"Afternoon\"\n",
    "    df.loc[df['Hour'] < 12, 'Phase'] = \"Morning\"\n",
    "    df.loc[df['Hour'] >= 18, 'Phase'] = \"Evening\"\n",
    "    \n",
    "    # Calculate approx durations\n",
    "    duration = 0\n",
    "    duration_col = []\n",
    "\n",
    "    for row in df.iterrows():\n",
    "        if row[1][subAct] == 1:\n",
    "            duration += 1\n",
    "        else:\n",
    "            duration = 0\n",
    "\n",
    "        duration_col.append(duration)\n",
    "\n",
    "    df['duration'] = duration_col\n",
    "\n",
    "    cancelled_interventions = 0\n",
    "    completed_interventions = 0\n",
    "    possible_intervention = False\n",
    "    intervening = False\n",
    "\n",
    "    total_minutes_saved = 0\n",
    "    total_kwh_saved = 0\n",
    "    total_dollars_saved = 0\n",
    "\n",
    "    for row in df.iterrows():\n",
    "        if row[1]['intervention'] and not intervening:\n",
    "            possible_intervention = True\n",
    "        if possible_intervention:\n",
    "            if row[1][subAct] == 0:\n",
    "                possible_intervention = False\n",
    "                cancelled_interventions += 1\n",
    "            else:\n",
    "                if row[1]['duration'] > benchmark_usage[subAct][row[1]['WDWE']][row[1]['Phase']] / 60:\n",
    "                    intervening = True\n",
    "                    completed_interventions += 1\n",
    "                    possible_intervention = False\n",
    "        if intervening:\n",
    "            if row[1][subAct] == 0:\n",
    "                intervening = False\n",
    "            else:\n",
    "                total_minutes_saved += 1\n",
    "                kwh_saved = wattage / 60\n",
    "                total_kwh_saved += kwh_saved\n",
    "                hour = row[1]['Hour']\n",
    "                wdwe = row[1]['WDWE']\n",
    "                rate = df_costs[(df_costs['Hour'] == hour) & (df_costs['WDWE'] == wdwe)].iloc[0]['cost_per_kwh']\n",
    "                dollars_saved = rate * kwh_saved\n",
    "                total_dollars_saved += dollars_saved\n",
    "\n",
    "    # We see that we didn't quite save as many minutes of electricity but we likely annoyed the user less\n",
    "    # Note that this means our 'confidence' value is going to be more conservative than it needs to be\n",
    "    print(\"SubAct:\",subAct)\n",
    "    print(\"Classifier confidence:\", confidence)\n",
    "    print(\"Number of completed interventions:\", completed_interventions)\n",
    "    print(\"Number of interventions cancelled due to not meeting average number of minutes usage:\", \n",
    "          cancelled_interventions)\n",
    "    print(\"Total minutes saved:\", total_minutes_saved)\n",
    "    print(\"Total minutes saved, accounting for confidence:\", total_minutes_saved * confidence)\n",
    "    print(\"Total electricity saved (kwh):\", total_kwh_saved)\n",
    "    print(\"Total electricity saved, accounting for confidence (kwh):\", total_kwh_saved * confidence)\n",
    "    print(\"Total money saved: $\", total_dollars_saved)\n",
    "    print(\"Total money saved accounting for confidence:  $\", total_dollars_saved * confidence)\n",
    "    print()\n",
    "    \n",
    "\n",
    "for row in df_sensors.iterrows():\n",
    "    subAct = row[1]['concat']\n",
    "    wattage = row[1]['wattage']\n",
    "    calc_subAct(df, subAct, wattage, df_costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jt -l\n",
    "# !jt -t <theme>\n",
    "# !jt -r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "863px",
    "width": "355px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
